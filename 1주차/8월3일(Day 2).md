# 1. 8월3일 공부한 것 정리!

## 2-2. Function and Console I/O

* 함수: 어떤 일을 수행하는 코드의 모음!

* print formatting

(1) % string

~~~
print('%s %s' %('one','two'))
# one two
~~~

(2) format 함수

~~~
print('{} {}'.format('one','two'))
#one two
~~~

(3) fstring

~~~
print(f"섭씨온도 : {cel_value:.2f}")
# 섭씨온도 : 10.00
~~~


## 2-3. Conditionals and Loops

### 조건문

: 조건에 따라 특정한 동작을 하게하는 명령어
  
  (예약어: else, if, elif)

* 조건 판단 방법

  * x<y: x가 y보다 작은지 비교
  * x>y: x가 y보다 큰지 비교
  * x==y: x와 y가 같은지 검사(값만!)
  * x is y: x와 y가 같은지 검사(값과 메모리 주소!)

~~~
a=300
b=300
a==b # False
a=b
a==b # True
~~~

: is는 메모리 주소를 비교함을 알 수 있다.


* fahrenheit type

~~~
cel_value = 100

print(f"섭씨온도 : {cel_value:.2f}") #100.00
print(f"화씨온도 : {(((9/5)*cel_value)+32):.2f}") #212.00
~~~

### 반복문

: 정해진 동작을 반복적으로 수행하게 하는 명령문

(for과 while 등으로 반복문 시행)


## 2-4. String and advanced function concept

### string

 : 문자열로 시퀀스 자료형이고 영문자 한 글자마다 1byte이 메모리 공간을 가진다.
 

* 각 타입 별 메모리 공간

|타입|크기|표현 범위|
|---|----|-------|
|int|4바이트+-2^31| -2^31 ~ 2^31-1|
|long|무제한|무제한|
|float|8바이트+-2^64| 10^(-308) ~ 10^308|

* slicing

~~~
a="arti"

print(a[::])
print(a[:-1])

#arti
#art
~~~

### 함수 호출

#### (1) 값에 의한 호출

: 함수에 값만 넘김

~~~
def f(x):
  x=13
  print(x) #13
a=7
f(a)
print(a) #7
~~~

=> immutable object인 int, float 등은 함수 argments로 넘어갈 때는 값에 의한 호출로 넘어감!


#### (2) 참조의 의한 호출

: 인자를 넘길 때 메모리 주소를 넘김


#### (3) 객체 참조에 의한 호출

: 객체의 주소가 함수로 전달된다.

~~~
def span(k):
  k.append(1)
  k.append(10)
z=[0]
span(z)
print(z)#[0,1,10]
~~~

=> mutable object인 list, dict, set과 같은 것이 argument로 넘어가면 object reference가 넘어가서 담고 있는 값을 바꿀 수 있다!


## 3-1. Python Data Structure

### Stack

: LIFO 형식으로 데이터가 나온다!

=> push는 append 명령어로, pop은 pop 명령어를 사용한다.


### Queue

: FIFO 형식으로 데이터가 나온다!

=> put을 append로, get을 pop(0)을 사용한다.(리스트 사용!)


### PriorityQueue

: 데이터 추가는 어떤 순서로 해도 상관이 없지만, 제거될 때는 가장 작은 값을 제거하는 독특한 특성을 지닌 자료구조

~~~
from queue import PriorityQueue

qu = PriorityQueue()
qu.put(4)
qu.put(1)
qu.put(2)

# get을 통해 요소 삭제 가능하다!
print(qu.get()) #1
print(qu.get()) #2
~~~


### tuple

: 리스트와 유사하지만 **값 변경이 불가능한** 리스트이다!

=> ()를 사용한다!

~~~
tuple = (3,4,5)

t[1]=5 # Error 발생 # 값 변경이 불가능하므로!
~~~


### 집합(set)

: set으로 선언하고 **중복이 안 된다!**

=> set()으로 선언하고 add, update로 추가하고 remove로 제거가 가능하다.

=> union 선언 시, 합집합이 되고 intersection 선언 시, 교집합이 된고 difference 선언 시, 차집합이 된다.


### 사전(dictionary)

: key와 value를 관리하는 자료구조로 고유 값인 key로 구분할 수 있다.

=> items() 명령 시, dictionary 데이터 출력이 가능하다! **(이 때, tuple 형태로 출력되니 변경 불가!)**

=> keys() 명령 시, dictionary 키 값 출력 가능하다.

=> values() 명령 시, dictionary value만 출력 가능하다.


### duque

: LinkedList의 특성을 지원한다!

=> deque()로 선언 가능하다!

=> appendleft() 시 가장 왼쪽에 추가 된다.


### OrderedDict

: 입력한 순서대로 dict를 반환한다! => 하지만 최근 python은 지원가능하다.

### Defaultdict

: 신규값 생성시 사용하는 방법이다!

=> 객체 생성 시, 함수 형태로 넣어서 선언해주면 그 값이 출력된다.

### Counter

: Sequence type의 data element를 세어준다!

=> Counter()로 선언하고 Counter 안에 list를 넣어주면 자동으로 각 element의 개수를 세어준다!


## 딥러닝 학습방법

* 비선형모델인 신경망은 **행벡터 = 데이터(xi) X 가중치 행렬(W) + 절편 b벡터**의 형태이다.

![zz](https://user-images.githubusercontent.com/59636424/127958484-8e7ff2db-579d-4794-bc4d-55d913b8480e.PNG)


X라는 행 벡터가 O라는 행 벡터와 연결 될 때, p개의 모델을 만들어야 하므로 총 화살표의 개수는 p X d개만큼의 화살표가 필요하다!

=> 이러한 p X d가 가중치 행렬 W이므로 이러한 화살표가 가중치 행렬의 역할이다!

![zz1](https://user-images.githubusercontent.com/59636424/127958536-5d2c113f-0e08-4380-8d70-506ddbbaab25.PNG)


### Softmax

![softmax](https://user-images.githubusercontent.com/59636424/127959075-adec046a-771e-4e3e-9900-b61dcf581827.PNG)

: **모델의 출력을 확률로 해석할 수 있게 해준다!!**

==> 분류 문제를 해결 시, 선형 모델 + 소프트 맥스를 결합해 해결한다!!

==> 사진의 o는 선형모델의 결과물이다. ==> 이것을 확률 벡터로 변환!

==> **추론 시, one-hot을 이용하면 된다! => 학습 시, 소프트 맥스 사용!**


### 활성 함수

* **신경망은 선형모델+활성함수인 함수**이다!

(활성함수는 하나의 실수값만 input으로 받는다 => 이 함수로 비선형 함수로 변환 가능하다! => 잠재 벡터, 히든 벡터, 뉴런)


* 활성 함수 종류

: sigmoid, relu, tanh가 있다. => relu가 가장 많이 사용된다!

![zzzzz](https://user-images.githubusercontent.com/59636424/127960135-49172ca9-b1c2-4834-a852-7bfe7a123b6c.PNG)

: 잠재벡터 H를 다시 출력으로 연결시키게 되면 선형 모델이 2개 이상이므로 2-layes 신경망이라고 한다.

=> 선형 모델과 활성화 함수를 반복적으로 사용되는 것이 현재 딥러닝 기본 모델이다!


* 다층 퍼셉트론(MLP)은 신경망이 여러층 합성된 함수이다!

* MLP의 파라미터는 L개의 가중치 행렬과 b의 절편 파리미터로 구성되어 있다.

* 층을 여러개 쌓는 이유는 층이 깊어질수록 목적함수를 근사하는데 필요한 뉴런의 개수가 빨리 줄어든다! -> **적은 파라미터로 복잡한 함수 표현!**


## 역전파 알고리즘

![역전파](https://user-images.githubusercontent.com/59636424/127961169-bf3c6ccf-deb0-48b9-8841-64bd47159d1a.PNG)

=> 미분 계산시 순차적으로 계산해야한다!

=> 빨간색 화살표가 각 층에서 계산된 gradient가 밑에 층에 전달 되며 업데이트 된다!

=> 윗층부터 역순으로 계산


### 연쇄법칙

=> 딥러닝 학습시키는 방법!

![ㅇㅇㅅㅅ](https://user-images.githubusercontent.com/59636424/127961634-ffcbee78-d4ad-4436-81a3-734146e10073.PNG)

(역전파 알고리즘 연쇄법칙 적용과정 - 빨간색: 역전파 미분 과정, 파란색 - 순전파 미분 과정)


## 확률론

### 확률 분포

![확률분포](https://user-images.githubusercontent.com/59636424/127962559-b7d2f450-5cbe-4e1f-afed-4749c0ac7cd6.PNG)

: 데이터 공간에 데이터를 추출하는 분포!


### 이산확률변수

: 확률변수고 가질 수 있는 경우의 수를 모두 고려하여 확률을 더해 모델링한다.

### 연속확률변수

: 데이터 공간에 정의된 확률변수의 밀도이다. => 적분을 통해 모델링한다.

=> 모델링 방법에 따라 이산확률변수나 연속확률변수로 사용할 수 있다.

### 조건부확률분포

: 입력 x와 출력 y 사이의 관계를 모델링한다.

=> 통계적 관계를 모델링 할 때, 사용할 수 있다.

=> softmax는 데이터 x로부터 추출된 패턴과 가중치 행렬 W를 통해 조건부확률 P(y|x) = P(y|패턴)을 계산할 수 있다.

=> 회귀 문제는 조건부기대값으로 추정한다.(회귀 문제에서는 손실함수를 L2 norm의 기댓값이라 조건부기대값이 이 L2 norm의 최솟값과 일치하므로 사용된다.)(아래 사진은 조건부기대값)

![조건부기대값](https://user-images.githubusercontent.com/59636424/127963801-9b5b8cb0-4f8b-4df0-acd6-433162f317ff.PNG)


### 기대값

: 확률분포가 주어질 때, 여러 종류의 통계적 범함수를 계산할 수 있다. => 데이터를 대표하는 통계량이다.

### 몬테카를로 샘플링

: 확률분포를 모를 때, 기대값을 계산할 시, 사용하는 방법으로 임의의 랜덤한 표본에서 시작하여, i번째 표본을 참고하여 i+1 번째 표본을 뽑는다.

![몬테카를로](https://user-images.githubusercontent.com/59636424/127964587-f6414b3e-a750-4bf8-8f46-ad5f1a733d96.PNG)

=> 몬테카를로 샘플링은 독립추출만 보장된다면 대수의 법칙으로 수렴성이 보장된다!!

==> 대수의 법칙에 의해, 일부 무작위 변수의 예상 값으로 설명되는 전체는 변수의 독립 표본의 평균(샘플 평균)을 취함으로써 근사치를 구할 수 있다.

* **대수의 법칙**이란? 표본집단의 크기가 커지면 그 표본평균이 모평균에 가까워짐을 의미한다!



(출처(객체 참조에 의한 호출): https://code13.tistory.com/214)

(출처(우선순위큐): https://www.daleseo.com/python-priority-queue/)

(출처(대수의 법칙): https://namu.wiki/w/%ED%81%B0%20%EC%88%98%EC%9D%98%20%EB%B2%95%EC%B9%99)

# 2. 피어세션 정리

- 피어세션이 피어씁니다 자료 제작

- 정해진 학습 내용에 국한되지 않고 공부를 하다가 개인적으로 필요를 느끼는 부분이 있다면 공부하여 공유

- 피어세션때 서로 진도가 다르면 이해가 어려우니 진도를 맞출 필요성이 필요하다

- python기초 보다는 AI Math를 중점으로 피어세션 진행

- 목요일까지 권장 학습 가이드만큼 끝내기

- 매주 월요일에 지난주 과제 리뷰

- 내일 (수) AI Math 6강 까지 공부하여 피어세션 참여

# 3. 과제 수행 과정 / 결과물 정리

## 필수 과제 4(BaseBall)

: 이 과제는 숫자야구 규칙을 줄여, 3자리 숫자를 맞추는 게임입니다. 우선, 문자열이 숫자로 이루어져 있는지 체크하는 함수는 isdigit를 이용하여 해결했습니다. 세자리 문자열 정수값이 중복된 숫자가 있는지 체크하는 함수는 이중 for문을 통해 체크했습니다.(이 함수 구현에서는 좋은 방법이 있을 것이라고 생각이 듭니다.) 스트라이크와 볼을 계산하는 함수는 result라는 배열에 index0은 strike, index1은 ball를 저장했고 유저가 입력한 숫자와 랜덤 숫자가 같다면 [3,0]을, 아니면 같은 index에 같은 값이 있다면 index0의 수를 증가시켰고, 아닌 index는 따로 각 유저 숫자와 랜덤 숫자를 저장했습니다. 그 따로 저장한 2개의 수로 비교해 같은 것이 있다면 index1인 balls를 증가시켜 result를 return 했습니다.

그리고 대밍의 이러한 함수로 main 함수를 짜게 되는데 많은 캠퍼들이 여기서 많이 막혔습니다. 왜냐하면 조건 중에, 0이 입력되면 프로그램을 종료해야 된다는 사실을 잘 인지하지 못 했고, 0은 꼭 다시 시작할 껀지 물을 때, 쓰는 것이 아니라 유저가 숫자를 입력할 때, 넣어야 프로그램이 제대로 돌아갈 수 있었습니다!

## 필수 과제 5(Morsecode)

: dictionary를 이용해 알파벳을 모스부호로, 모스부호를 알파벳으로 바꾸는 프로그램을 만드는 과제입니다. 이 과제 역시, 필요 없는 특수 문자, 문자, 띄어쓰기를 정규화 re를 통해 제거하게 dictioary의 keys, items 명령을 통해 바꾸어 과제를 수행했습니다.

# 4. 학습회고

: 오늘은 과제에서 생각보다 많은 시간을 쏟았지만, 한 번더 정규화를 통한 문자열 처리를 다시 해 볼 수 있었습니다. 확률론과 역전파는 아직 확실히 공부가 된 거 같지 않아 계속 복습이 필요할 것 같습니다.
