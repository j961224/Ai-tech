# 1. 8월 4일 정리

## 3-2. Pythonic code

### split

: 어떠한 기준으로 string을 자른다!

### lambda

~~~
(lambda x, y : x+y)(10, 50)
#60
~~~

- 테스트의 어려움과 코드 해석의 어려움이 있다!

### 가변인자

- * args 변수명으로 사용된다!

~~~
def test(a,b,* args):
  print(list(args))
  print(type(args)) # 튜플로 받는다!
  return a+b+sum(args)
 
test(1,2,3,4,5)
#[3,4,5]
#<class 'tuple'>
#15
~~~

### Keyword argument

~~~
def test(a,b,* args, ** kwargs):
  print(list(args))
  print(type(args)) # 튜플로 받는다!
  print(kwargs)
  return a+b+sum(args)
  
 
test(1,2,3,4,5,first=3, second=4) #가변 인자 순서를 지켜야한다!
#[3,4,5]
#<class 'tuple'>
#{'first':3, 'second':4}
#15
~~~

## 4-1. Python OOP

- 객체: 속성과 행동을 가진다! => class와 instance로 나눈다!

- snake_case: 띄어쓰기 부분에 _ 를 추가!

- CamelCase: 파이썬 class 이름 사용!

- __init__ 은 객체 초기화 예약 함수!


### 객체 지향 언어의 특징

#### 1. inheritance

: 부모클래스 속성을 받은 자식 클래스 생성

#### 2. Polymorphism

: 같은 이름의 메소드를 내부에 로직을 다르게 만드는 것이다.

#### 3. Visibility

: 누구나 볼 필요는 없으므로 객체의 정보를 볼 수 있는 레벨을 조정하는 것!

- inner function

: 함수 내에 또 다른 함수가 존재한다!


## 4-2. Module and Project

### Module

: 프로그램에서 사용되는 작은 프로그램 조각들!

~~~
import python 파일
~~~


### namespace

: 모듈을 호출할 때, 범위 정하는 방법!

==> 원하는 부분을 불러옴(모든 코드 로딩 방지)

- Alias 설정 방법: 별칭 사용하기

~~~
import 파이썬 파일 as ha 
print(ha,convert_c_to_f(41))
~~~

- 모듈에서 특정 함수 호출

~~~
from 파이썬 파일 import 함수
~~~

- 모듈에서 모든 함수 or 클래스 호출

~~~
from 파이썬 파일 import *
~~~

### 패키지

: 코드의 묶음으로 모듈의 합이다.

=> 보통 각 파일에 코드들을 넣는데 하나의 파일이 패키지라고 생각하면 된다.

~~~
from ~~ import test() # import는 절대 참조

from .render import test() # from 뒤에 .은 현재 디렉토리 기준!

from ..ss.echo impor test() # from 뒤에 ..은 부모 디렉토리 기준!
~~~

### 가상환경

: 필요한 패키지만 설치하는 환경!

#### 패키지 관리 도구

- **virtualenv+pip**: 가장 대표적인 가상환경 관리 도구(레퍼런스+패키지 개수) (pip는 compile된 코드가 안 들어가 있는 경우가 있다.)

- **conda**: 상용 가상환경도구 -> 컴파일된 코드가 있다! -> Windows에서 좋다!

~~~
conda create -n my project python=3.8
#conda create: 가상환경 새로 만들기
#-n my project: 가상환경 이름
#python=3.8: 파이썬 버전
~~~

## 7. 통계학

- 모수: 적절한 가정 위에서 확률분포를 추정

- 모수적방법: 데이터가 확률분포를 따른다고 가정한 후, 분포를 결정하는 모수 추정 방법

- 비모수방법: 데이터가 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌는 방법 => 모수를 쓰지 않는 것이 아니라 엄청 많을 수 있다.

### 확률분포 가정

#### 베르누이 분포

: 데이터가 2개의 값만 가지는 경우

#### 카테고리분포

: 데이터가 n개의 이산적인 값을 가지는 경우

#### 베타분포

: 데이터가 [0,1] 사이에서 값을 가지는 경우

#### 정규분포

: 데이터가 R 전체에서 값을 가지는 경우

==> 데이터를 생성하는 원리를 보고 위의 원칙을 결정하는 것이 원칙이다!


#### 확률분포 가정 시, 평균과 분산

![zzz](https://user-images.githubusercontent.com/59636424/128121382-7cc86a98-7a7b-43b1-bc7a-00150409aa0f.PNG)

: 표본 분산을 구할 시, N-1로 나누는 이유는 불편 추정량을 구하기 위해서다!


* **표집분포**

: 통계량의 확률분포이고 **표본평균의 표집분포는 N이 커질수록 정규분포를 따른다!!**


#### 최대가능도추정법

![zzzz](https://user-images.githubusercontent.com/59636424/128121721-ef929c84-f933-4799-9fab-6b892215319f.PNG)

: 가장 가능성 높은 모수를 추정하는 방법이다.

==> 주어진 데이터 x에 대해서 모수 세타를 변수를 둔 함수이다. (데이터가 주어져 있는 상황에서 세타를 변형시킴에 따라, 변형된다.)


#### 로그가능도

![log가능도](https://user-images.githubusercontent.com/59636424/128122035-9442c650-e248-45db-944d-7b42ee3bf931.PNG)

: 데이터 집합 X가 독립적으로 추출되었을 경우, 로그가능도를 최적화한다.

-> 곱셈이 아닌 덧셈!

==> 데이터가 숫자가 엄청 키다면 계산이 불가능하다. => 그래서 로그가능도를 사용해 최적화시킨다.

-> 손실함수는 경사하강법을 사용하므로, 목적식을 최소화시키므로 **음의 로그가능도**를 사용해 최적화시킨다.


#### 최대가능도 추정법: 정규분포

![정규분포로그화](https://user-images.githubusercontent.com/59636424/128122505-f8cae3fa-e018-4ef3-9443-50299a697151.PNG)

-> 세타 대신에 평균과 분산을 가지고 계산한다.

-> 가능도함수의 모양이 **확률밀도함수**와 같은 모양인 것은 정규분포의 확률밀도함수가 가지는 성질로 확률밀도함수가 사용되었다.


![ㅋㅋㅋㅋㅋㅋ](https://user-images.githubusercontent.com/59636424/128123640-14e90a00-d46b-4417-b236-d6d9fb86d193.PNG)

-> 평균과 시그마를 미분해주면 이와 같은 수식을 얻게 되고 0인 시점의 평균과 분산을 구하게 되면 로그가능도의 최대화해주는 모수를 찾는다!

=> 정규분포로그화 사진에서 오른쪽에 있는 수식만 살아남는다!(위의 사진의 첫 번째 수식)


#### 최대가능도 추정법: 카테고리 분포

![ㅋㅌㄱㄹ](https://user-images.githubusercontent.com/59636424/128124150-97668040-2f46-4f8f-bfc6-4dea75e75f58.PNG)

: 카테고리 분포의 p1 ~ pd는 각각 값이 1 또는 0이 되는 확률이므로 총 합은 1이다.

-> nk는 주어진 데이터 xi에 대해서 k값이 1인 데이터의 개수

![ㅋㅋㅋㄷㄱ](https://user-images.githubusercontent.com/59636424/128124468-6f28137e-3a9f-417f-92bd-113cdc4249a0.PNG)

--> 목적식에 제약식을 더해 새로운 목적식을 만들어 제약식도 만족하고 로그가능도도 최적화시킨다.(첫째줄 오른쪽 수식)

--> n은 데이터 개수와 같다.


### 확률분포 거리 구하기

#### 쿨백-라이블러 발산

![kl](https://user-images.githubusercontent.com/59636424/128125204-d9603920-b5b7-4de4-8ab5-bc0f4ed1cb48.PNG)

: 분류문제에서 정답레이블을 P, 모델 예측을 Q라 두면 최대가능도 추정법에 사용되는 손실함수은 쿨백-라이블러에서 첫 번째의 크로스 엔트로피의 마이너스와 같다.

=> P와 Q 사이의 거리와 동일하다. (확률분포 사이 거리 최소화 개념, 로그가능도 함수 최대화시키는 것과 밀접)

* **최대 가능도 추정법은 쿨백-라이블러 발산을 최소화하는 것이다!**

* 쿨백-라이블러 발산이 0이면 두 확률분포는 같은 확률분포이다!

KL(p||q)=0↔p=q


## 8. 베이즈 통계학

### 조건부 확률

![qdw](https://user-images.githubusercontent.com/59636424/128126800-f826a552-241b-4e0e-a55c-9f3cc57e1bfc.PNG)

: 사건 B가 일어난 상황에서 사건 A가 발생할 확률

### 베이즈 정리

![qpdmw](https://user-images.githubusercontent.com/59636424/128126993-010cf665-1037-4f8a-8537-d1addeaf1a7d.PNG)

: 사후확률를 구하기 위해서는 사전확률을 가지고 베이즈 정리를 통해 구한다!!

-> 사후확률: 데이터가 주어졌을 때, 파라미터가 성립할 확률

-> 사전확률: 데이터가 주어지지 않는 상황에서, 세타에 대한 확률(데이터 분석 전 가설)

-> evidence: 데이터 자체에 대한 분포

-> likelihood: 현재 주어진 모수에 대해 데이터가 관찰된 확률


* 베이즈 정리 예제

![베이즈 구하는 예시](https://user-images.githubusercontent.com/59636424/128127750-b8835f5d-a380-4972-a68c-ecae30279638.PNG)


* 조건부확률로 인과관계만으로 높은 예측 정확도를 예측하기는 어렵다.

* 인과관계를 알아내는데 **중첩요인 효과**를 제거하고 계산해야 한다.

(최대가능도 추정법 관련 잘 설명된 link: https://datascienceschool.net/02%20mathematics/09.02%20%EC%B5%9C%EB%8C%80%EA%B0%80%EB%8A%A5%EB%8F%84%20%EC%B6%94%EC%A0%95%EB%B2%95.html)

(쿨백-라이블러 잘 설명된 link: https://datascienceschool.net/02%20mathematics/10.03%20%EA%B5%90%EC%B0%A8%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC%EC%99%80%20%EC%BF%A8%EB%B0%B1-%EB%9D%BC%EC%9D%B4%EB%B8%94%EB%9F%AC%20%EB%B0%9C%EC%82%B0.html)
