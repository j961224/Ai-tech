# 1. 8월 4일 정리

## 3-2. Pythonic code

### split

: 어떠한 기준으로 string을 자른다!

### lambda

~~~
(lambda x, y : x+y)(10, 50)
#60
~~~

- 테스트의 어려움과 코드 해석의 어려움이 있다!

### 가변인자

- * args 변수명으로 사용된다!

~~~
def test(a,b,* args):
  print(list(args))
  print(type(args)) # 튜플로 받는다!
  return a+b+sum(args)
 
test(1,2,3,4,5)
#[3,4,5]
#<class 'tuple'>
#15
~~~

### Keyword argument

~~~
def test(a,b,* args, ** kwargs):
  print(list(args))
  print(type(args)) # 튜플로 받는다!
  print(kwargs)
  return a+b+sum(args)
  
 
test(1,2,3,4,5,first=3, second=4) #가변 인자 순서를 지켜야한다!
#[3,4,5]
#<class 'tuple'>
#{'first':3, 'second':4}
#15
~~~

## 4-1. Python OOP

- 객체: 속성과 행동을 가진다! => class와 instance로 나눈다!

- snake_case: 띄어쓰기 부분에 _ 를 추가!

- CamelCase: 파이썬 class 이름 사용!

- __init__ 은 객체 초기화 예약 함수!


### 객체 지향 언어의 특징

#### 1. inheritance

: 부모클래스 속성을 받은 자식 클래스 생성

#### 2. Polymorphism

: 같은 이름의 메소드를 내부에 로직을 다르게 만드는 것이다.

#### 3. Visibility

: 누구나 볼 필요는 없으므로 객체의 정보를 볼 수 있는 레벨을 조정하는 것!

- inner function

: 함수 내에 또 다른 함수가 존재한다!


## 4-2. Module and Project

### Module

: 프로그램에서 사용되는 작은 프로그램 조각들!

~~~
import python 파일
~~~


### namespace

: 모듈을 호출할 때, 범위 정하는 방법!

==> 원하는 부분을 불러옴(모든 코드 로딩 방지)

- Alias 설정 방법: 별칭 사용하기

~~~
import 파이썬 파일 as ha 
print(ha,convert_c_to_f(41))
~~~

- 모듈에서 특정 함수 호출

~~~
from 파이썬 파일 import 함수
~~~

- 모듈에서 모든 함수 or 클래스 호출

~~~
from 파이썬 파일 import *
~~~

### 패키지

: 코드의 묶음으로 모듈의 합이다.

=> 보통 각 파일에 코드들을 넣는데 하나의 파일이 패키지라고 생각하면 된다.

~~~
from ~~ import test() # import는 절대 참조

from .render import test() # from 뒤에 .은 현재 디렉토리 기준!

from ..ss.echo impor test() # from 뒤에 ..은 부모 디렉토리 기준!
~~~

### 가상환경

: 필요한 패키지만 설치하는 환경!

#### 패키지 관리 도구

- **virtualenv+pip**: 가장 대표적인 가상환경 관리 도구(레퍼런스+패키지 개수) (pip는 compile된 코드가 안 들어가 있는 경우가 있다.)

- **conda**: 상용 가상환경도구 -> 컴파일된 코드가 있다! -> Windows에서 좋다!

~~~
conda create -n my project python=3.8
#conda create: 가상환경 새로 만들기
#-n my project: 가상환경 이름
#python=3.8: 파이썬 버전
~~~

## 7. 통계학

- 모수: 적절한 가정 위에서 확률분포를 추정

- 모수적방법: 데이터가 확률분포를 따른다고 가정한 후, 분포를 결정하는 모수 추정 방법

- 비모수방법: 데이터가 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌는 방법 => 모수를 쓰지 않는 것이 아니라 엄청 많을 수 있다.

### 확률분포 가정

#### 베르누이 분포

: 데이터가 2개의 값만 가지는 경우

#### 카테고리분포

: 데이터가 n개의 이산적인 값을 가지는 경우

#### 베타분포

: 데이터가 [0,1] 사이에서 값을 가지는 경우

#### 정규분포

: 데이터가 R 전체에서 값을 가지는 경우

==> 데이터를 생성하는 원리를 보고 위의 원칙을 결정하는 것이 원칙이다!


#### 확률분포 가정 시, 평균과 분산

![zzz](https://user-images.githubusercontent.com/59636424/128121382-7cc86a98-7a7b-43b1-bc7a-00150409aa0f.PNG)

: 표본 분산을 구할 시, N-1로 나누는 이유는 불편 추정량을 구하기 위해서다!


* **표집분포**

: 통계량의 확률분포이고 **표본평균의 표집분포는 N이 커질수록 정규분포를 따른다!!**


#### 최대가능도추정법

![zzzz](https://user-images.githubusercontent.com/59636424/128121721-ef929c84-f933-4799-9fab-6b892215319f.PNG)

: 가장 가능성 높은 모수를 추정하는 방법이다.

==> 주어진 데이터 x에 대해서 모수 세타를 변수를 둔 함수이다. (데이터가 주어져 있는 상황에서 세타를 변형시킴에 따라, 변형된다.)


#### 로그가능도

![log가능도](https://user-images.githubusercontent.com/59636424/128122035-9442c650-e248-45db-944d-7b42ee3bf931.PNG)

: 데이터 집합 X가 독립적으로 추출되었을 경우, 로그가능도를 최적화한다.

-> 곱셈이 아닌 덧셈!

==> 데이터가 숫자가 엄청 키다면 계산이 불가능하다. => 그래서 로그가능도를 사용해 최적화시킨다.

-> 손실함수는 경사하강법을 사용하므로, 목적식을 최소화시키므로 **음의 로그가능도**를 사용해 최적화시킨다.


#### 최대가능도 추정법: 정규분포

![정규분포로그화](https://user-images.githubusercontent.com/59636424/128122505-f8cae3fa-e018-4ef3-9443-50299a697151.PNG)

-> 세타 대신에 평균과 분산을 가지고 계산한다.

-> 가능도함수의 모양이 **확률밀도함수**와 같은 모양인 것은 정규분포의 확률밀도함수가 가지는 성질로 확률밀도함수가 사용되었다.


![ㅋㅋㅋㅋㅋㅋ](https://user-images.githubusercontent.com/59636424/128123640-14e90a00-d46b-4417-b236-d6d9fb86d193.PNG)

-> 평균과 시그마를 미분해주면 이와 같은 수식을 얻게 되고 0인 시점의 평균과 분산을 구하게 되면 로그가능도의 최대화해주는 모수를 찾는다!

=> 정규분포로그화 사진에서 오른쪽에 있는 수식만 살아남는다!(위의 사진의 첫 번째 수식)


#### 최대가능도 추정법: 카테고리 분포

![ㅋㅌㄱㄹ](https://user-images.githubusercontent.com/59636424/128124150-97668040-2f46-4f8f-bfc6-4dea75e75f58.PNG)

: 카테고리 분포의 p1 ~ pd는 각각 값이 1 또는 0이 되는 확률이므로 총 합은 1이다.

-> nk는 주어진 데이터 xi에 대해서 k값이 1인 데이터의 개수

![ㅋㅋㅋㄷㄱ](https://user-images.githubusercontent.com/59636424/128124468-6f28137e-3a9f-417f-92bd-113cdc4249a0.PNG)

--> 목적식에 제약식을 더해 새로운 목적식을 만들어 제약식도 만족하고 로그가능도도 최적화시킨다.(첫째줄 오른쪽 수식)

--> n은 데이터 개수와 같다.


### 확률분포 거리 구하기

#### 쿨백-라이블러 발산

![kl](https://user-images.githubusercontent.com/59636424/128125204-d9603920-b5b7-4de4-8ab5-bc0f4ed1cb48.PNG)

: 분류문제에서 정답레이블을 P, 모델 예측을 Q라 두면 최대가능도 추정법에 사용되는 손실함수은 쿨백-라이블러에서 첫 번째의 크로스 엔트로피의 마이너스와 같다.

=> P와 Q 사이의 거리와 동일하다. (확률분포 사이 거리 최소화 개념, 로그가능도 함수 최대화시키는 것과 밀접)

* **최대 가능도 추정법은 쿨백-라이블러 발산을 최소화하는 것이다!**

* 쿨백-라이블러 발산이 0이면 두 확률분포는 같은 확률분포이다!

KL(p||q)=0↔p=q


## 8. 베이즈 통계학

### 조건부 확률

![qdw](https://user-images.githubusercontent.com/59636424/128126800-f826a552-241b-4e0e-a55c-9f3cc57e1bfc.PNG)

: 사건 B가 일어난 상황에서 사건 A가 발생할 확률

### 베이즈 정리

![qpdmw](https://user-images.githubusercontent.com/59636424/128126993-010cf665-1037-4f8a-8537-d1addeaf1a7d.PNG)

: 사후확률를 구하기 위해서는 사전확률을 가지고 베이즈 정리를 통해 구한다!!

-> 사후확률: 데이터가 주어졌을 때, 파라미터가 성립할 확률

-> 사전확률: 데이터가 주어지지 않는 상황에서, 세타에 대한 확률(데이터 분석 전 가설)

-> evidence: 데이터 자체에 대한 분포

-> likelihood: 현재 주어진 모수에 대해 데이터가 관찰된 확률


* 베이즈 정리 예제

![베이즈 구하는 예시](https://user-images.githubusercontent.com/59636424/128127750-b8835f5d-a380-4972-a68c-ecae30279638.PNG)


* 조건부확률로 인과관계만으로 높은 예측 정확도를 예측하기는 어렵다.

* 인과관계를 알아내는데 **중첩요인 효과**를 제거하고 계산해야 한다.

(최대가능도 추정법 관련 잘 설명된 link: https://datascienceschool.net/02%20mathematics/09.02%20%EC%B5%9C%EB%8C%80%EA%B0%80%EB%8A%A5%EB%8F%84%20%EC%B6%94%EC%A0%95%EB%B2%95.html)

(쿨백-라이블러 잘 설명된 link: https://datascienceschool.net/02%20mathematics/10.03%20%EA%B5%90%EC%B0%A8%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC%EC%99%80%20%EC%BF%A8%EB%B0%B1-%EB%9D%BC%EC%9D%B4%EB%B8%94%EB%9F%AC%20%EB%B0%9C%EC%82%B0.html)

# 2. 피어세션 정리

- 변자민님, 서현범님 입과 취소

- 선형회귀 계수 수식 풀어보기

- 중심극한정리 사이트: https://angeloyeo.github.io/2020/09/15/CLT_meaning.html

- CV 대회 우수 코드: https://programmers.co.kr/skill_check_assignments/133

- 모두 AI Math 8강까지 강의 듣기 완료 / 필수 관제 완료 / AI Math 학습 정리 -ing

- 내일(목)

- 학습정리 깃허브 비공개로 올리는 중인데, 운영진분들의 깃허브 아이디 읽기권한 드리는 되는지

- 선택 과제 풀고 어려운 부분 묻기


# 3. 과제 수행 과정 / 결과물 정리

## 선택 과제(Gradient Descent)

: 이 과제는 Gradient Descent를 구현, 변화율에 따른 Gradient Descent 구현, Gradeint Descent를 이용한 Linear Regression 구현, 더 복잡한 선형식에 대한 Regression 구현, SGD 구현하는 과제입니다.

**우선**, Gradient Descent 구현은 함수를 받아 함수를 x에 대해 미분하고 미분한 함수와 미분한 함수에 변수를 넣은 값 이렇게 2개의 값을 return 하는 함수를 만들었습니다. 그리고 Gradient Descent를 실질적으로 구하는 함수에는 위의 함수를 통해 미분한 함수에 변수를 넣은 값을 구합니다. 이 값이 epsilon보다 작아지면 원하는 값에 근접하기에 계산을 멈춰 구한 최소점을 return 합니다. 그리고 epsilon이 작아질 때까지, 계속 미분한 함수에 변수를 넣은 값에 learning rate를 곱해 초기점을 저장한 변수와 빼면서 갱신합니다. 그 초기점을 저장했던 변수를 다시 미분함수에 변수를 넣는 값을 구하는 함수에 넣으면서 반복합니다.

* Gradient Descent 구현 결과

![결과1](https://user-images.githubusercontent.com/59636424/128506250-3d2e484e-24ab-496f-8f25-aacce9b5b60a.PNG)

: 결과로 최소점이 (-1,2)에 가까우면 되는데 매우 가까움을 알 수 있습니다. 

**다음으로**, 위와 같은 방법으로 변화율을 계산해 Gradient Descent를 구하는 문제입니다. 

![ㅋㅋㅋ](https://user-images.githubusercontent.com/59636424/128506487-fc036ea3-3cc4-46ac-959f-14e150e86a91.PNG)

위와 같은 수식을 코드로 옮겨 변화율 계산 함수 fun을 구합니다. 그리고 위의 방식과 똑같이 하는데 대신, fun함수를 이용해서 변화율을 계산합니다.

* difference quotient를 이용해 Gradient Descent 구현 결과

![ㅋㅋㅋㅋㅋ](https://user-images.githubusercontent.com/59636424/128506714-5628dab9-fa61-4093-96fc-0c4b1f5e28e9.PNG)

**다음으로**, linear regressiong을 구하는 문제입니다. 우선 예측값 yy를 W X x + b의 식을 이용해 구합니다. 그리고 gradient_w는 x의 값과 연관이 있으므로 실제값 y와 예측값 yy를 뺀 상태에 x의 값을 곱하고 learning rate도 곱하여 평균값으로 구합니다. 또한 gradient_b는 실제값 y와 예측값 yy를 뺀 상태에 learning rate를 곱해 평균값으로 구합니다. 이러한 값을 각각 w와 b에 빼서 갱신시킵니다. 그리고 error는 실제값 y와 예측값 yy와 빼고 제곱한 L2 norm을 이용하고 그거의 합들을 error에 저장하는 방식으로 구했습니다.

* linear regression 구현 결과

![구현1](https://user-images.githubusercontent.com/59636424/128507491-63d920f9-e42e-44c6-b84d-4a743acb059e.PNG)

: w와 b가 그래도 7과 2에 어느정도 가까움을 보여줍니다.

![구현2](https://user-images.githubusercontent.com/59636424/128507496-8b983961-78db-4014-a327-fcd1ac27651a.PNG)

: error 변화율을 보여주는 그래프로 매끄럽게 내려가는 것을 확인할 수 있습니다.

**다음으로**, 다차원에서의 Regression을 구현하는 문제입니다. 우선, error는 y의 값에 x와 beta_gradient 곱한 값을 뺀 값입니다. 그 값을 transpose한 x와 error를 곱하고 -를 붙여 gradient를 구합니다. 그리고 beta_gradient에 -0.01 X gradient한 값을 더해 beta_gradient를 갱신한다. 아래와 같은 식을 코드로 구현한 것입니다.

![이거다](https://user-images.githubusercontent.com/59636424/128508518-8d29e0f2-bd54-43dc-908c-54e257a25f70.PNG)

* 복잡한 선형식에 대한 Regression 결과

![결과1](https://user-images.githubusercontent.com/59636424/128508662-446499ec-f959-4d71-af9b-b185fb0b232b.PNG)

: beta_gd는 1,3,5,7과 매우 유사함을 알 수 있습니다.

**마지막으로**, SGD를 구현하는 문제이다. 앞서, Gradient Descent를 구현한 방법이랑 매우 유사하다. 여기서 mini-batch를 넣어 그 값을 구하는 코드만 추가하여 구현했습니다.

* SGD 결과

![구현1](https://user-images.githubusercontent.com/59636424/128509009-2b7d629f-e62c-47e7-8321-aa5024945ffa.PNG)

: Gradient Descent와 마찬가지로, (7,2)에 가까운 값이 나옴을 알 수 있습니다.

![구현2](https://user-images.githubusercontent.com/59636424/128509006-46c0d9ea-cea3-4c4c-a2a1-c74b8f73fab6.PNG)

: Gradient Descent는 error가 줄어듦이, 데이터를 모두 사용하기에 매끄럽지만 SGD는 수렴속도가 빠르지만 그래프가 매끄럽지 않음을 알 수 있습니다.



# 4. 학습 회고

: 이번 시간에는 통계학과 베이즈 통계학을 배운 부분이 아직 수식들이 익숙치 않아 이해가 조금 힘들었습니다. 또한, 선택 과제를 통해 Gradient Descent를 다시 1번 뜯어보고 Linear Regression을 구하는 부분도 다시 한 번 상기시킬 수 있었습니다.

