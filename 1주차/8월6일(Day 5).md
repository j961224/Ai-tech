# 1. 8월 6일 정리

## 5-2. Python data handling

### CSV

: 콤마를 데이터로 나눈 값


**엑셀 양식의 데이터를 프로그램에 상관없이 쓰기 위한 데이터 형식!**

### Web

데이터 송수신을 위한 HTTP 프로토콜을 사용학 데이터를 표시하기 위해 **HTML 형식**을 사용한다.

### HTML

: 웹 상의 정보를 구조적으로 표현하기 위한 언어

제목, 단락, 링크 등 요소 표시를 위해 Tag를 사용한다!

모든 요소들은 꺾쇠 괄호 안에 둘러 쌓여 있음 -> markup 언어이다!

==> string, regex, beautifulsoup으로 분석 가능하다.


### 정규식

: 복잡한 문자열 패턴을 정의하는 **문자 표현 공식**


* 문자 클래스 []

: [ 와 ] 사이의 문자들과 매치라는 의미

* ?

: 반복횟수가 1회인 경우

~~~
(http)(.+)(zip) #첫번째와 마지막이 http으로 시작, zip으로 끝나고 그 사이는 뭐든 상관없다는 뜻
~~~

### 정규식 in 파이썬

- import re를 사용

  - search: 한 개만 찾기
  - findall: 전체 찾기
  - 추출된 패턴은 tuple로 반환됨

~~~
import re
import urllib.request

url = "http://goo.gl/U7mSQl"
html = urllib.request.urlopen(url)
html_contents = str(html.read())

id_results = re.findall(r"([A-Za-z0-9]+\*\*\*)",html_contents)
print(id_results)
~~~

~~~
import re
import urllib.request

url = "https://finance.naver.com/item/main.nhn?code=005930"
html = urllib.request.urlopen(url)
html_contents = str(html.read().decode("ms949"))

stock_result=re.findall("(\<dl class=\"blind\"\>)([\s\S]+?)(\<\/dl\>)",html_contents)

samsung_stock = stock_result[0]
samsung_index = samsung_stock[1]

index_list = re.findall("(\<dd\>)([\s\S]+?)(\<\/dd\>)",samsung_index)

for index in index_list:
  print(index[1])
~~~

### XML

: 데이터의 구조와 의미를 설명하는 TAG를 사용!

### BaeutifulSoup

: HTML, XML 등 마크업 언어 스크랩핑을 위한 대표적 도구!


### JSON

: 데이터 저장 및 읽기는 dict type으로 상호 호환 가능


## Numpy part

### array creation

~~~
a = np.array(a)
b = np.array(b)
a[0] is b[-1] #False

# a[0]와 b[-1]은 서로 다른 메모리 주소를 가지므로, numpy.ndarray에서는 새로운 값을 할당하기 때문에 메모리 비교시 다름! 
~~~

* dtype: array 배열 전체의 데이터 type을 반환함

* array의 rank에 따라 불리는 이름이 있다!!

|Rank|Name|Example|
|-----|----|------|
|0|scalar|7|
|1|vector|[10,10] -> 1차원|
|2|matrix|[[10,10],[15,15]] -> 2차원|
|3|3-tensor|[[[1,5,9],[2,6,10]],[[3,7,11],[4,8,12]]] -> 3차원|
|n|n-tensor| n차원|

* shape: array의 크기, 형태 등의 정보

* nbytes: ndarray oject의 메모리 크기를 반환!

### Handling shape

* reshape: array의 shape의 크기를 변경하지만 데이터의 개수는 동일하다.

reshape(-1,2) -> element가 8개라면 열이 2이므로 자동으로 행은 4로 지정된다!

* arange: array의 범위를 정해서, 값의 list를 생성하는 명령어!

* empty: shape만 주어지고 비어있는 ndarray 생성! -> memory initialization이 되지 않는다!!
  
  빈 공간만 잡아서 쓴다!

* identity: 단위 행렬을 생성!

~~~
np.identity(n-3, dtype = np.int8)
~~~

* eye: 대각선인 1인 행렬, k값으로 시작 index의 변경 가능!

* diag: 대각선 행렬의 값만 추출!


### operation function

* concatenate: array끼리 붙이는 것!

~~~
vstack: row로 아래에 붙음
hstack: column에 왼쪽에 붙음

concatenate: axis=0은 아래(row)로 붙고 axis=1은 옆(column)에 붙음
~~~

* newaxis: 값은 그대로면서 축이 추가된다!

~~~
b = np.array([5,6])
b[np.newaxis,:] #array([[5,6]])
~~~

### array operation

: +로 가능하다!

* element-wise operations: array간에 shape이 같을 때, 같은 위치끼리 계산이 된다!

* transpose: 전치해준다!

* boradcasting: shape이 다른 배열 간 연산을 지원한다!

~~~
scaler = 3
test = np.array([1,2],[3,4])

test+scaler # array([4,5],[6,7])
~~~

* timeit으로 성능을 측정할 수 있다!!


### comparisons

* all과 any: all은 하나라도 조건과 다르면 False, any는 조건이 하나라도 맞으면 True

* np.where: 조건에 맞는 index를 보여준다!

* argsort

* np.argmax(): 가장 큰 값의 index를 추출!

~~~
a=np.array([3,4,5])
a.argsort()
#array([0,1,2])
~~~

|boolean index|fancy index|
|----|----|
|특정 조건에 따른 값을 추출하며 조건이 True인 index의 element만 추출|index값을 넣어서 값을 추출|
|불린 list를 쓴다|integer list사용|
|불린 index를 쓰려면 원래 array와 불린 index shape이 같아야 한다.|같을 필요는 없고 적어도 원래 array의 범위만큼만은 지정되야한다.|

~~~
a.take(b) # fancy index 효과와 같다.
~~~

### loadtxt & savetxt

- loadtxt: 불러와서 쓰기

- savetxt: 저장하고 싶은 파일명으로 저장할 수 있다.

## 7-1. pandas 1

: 구조화된 데이터의 처리를 지원하는 python 라이브러리

* **series**: DataFrame 중 하나의 column에 해당하는 데이터의 모음 object
  
  - column vector를 표현하는 object이다!
  - 기본적으로 series는 index가 기준이 된다.

* **dataframe**

  - column을 선택하여 series를 추출할 수 있다.

~~~
df.loc[:,['column이름']]
# 해당 컬럼에 대한 정보 추출
~~~

~~~
s.iloc[:3] # 앞에 3개 행 추출
~~~

### selection and drop

#### selection

~~~
df["account"].head(3) # 컬럼 이름을 가지고 가져올 수 있다.
df["account"] # series 형태
df[["account"]] # dataframe 형태

df.index로 index 관리 가능!
~~~

* df.drop 시, inplace 사용 시에 깔끔히 삭제 가능

* replace: Map 함수 기능 중 데이터 변환 기능만 담당

~~~
df.sex.replace({'male':0,'female':1},inplace=True) # inplace를 넣어야 변경됨
~~~

* apply

~~~
f = lambda x: x**2
df_info["earn"].apply(f) # 해당 컬럼에 다 적용이 된다.
~~~

* df.sort_values: 해당 컬럼에 대해 정렬

## 7-2. pandas part 2

### groupby

: split -> apply -> combine 과정을 거쳐 연산을 한다!

* **형식: df.groupby("Team")["Points"].sum() -> 묶음의 기준이 되는 컬럼, 적용받는 컬럼, 적용받는 연산**

* unstack: 데이터를 matrix형태로 풀어준다!

#### grouped

: 그룹되어 있는 상태로만 받을 수 있다.

~~~
for name, group in grouped:
  print(name)
  print(group)

# tuple 형태로 그룹의 key 값과 value 값이 추출된다!!
~~~

* get_group: 특정 그룹의 형태를 받을 수 있다.

* aggregation: 요약된 통계 정보를 추출해준다.

* Transformation: 해당 정보를 변환해준다. (aggregation과 달리 key값 별로가 아닌 개별 데이터에 지정)

* Filtration: 특정 정보를 제거하여 보여주는 필터링 기능 (특정 조건으로 데이터를 검색할 때 사용)

~~~
# aggregation

grouped.agg(np.mean)
# 컬럼별로 하는데 그룹별로 값을 보여준다!

grouped['Points'].agg([np.sum, np.mean, np.std])

# 위의 3개의 연산을 컬럼으로 각 그룹마다 값을 보여준다
~~~

~~~
score = lambda x : (x.max())
grouped.transform(score) # 모든 값에 score 지정
~~~

~~~
df.groupby("Team").filter(lambda x : len(x) >=3) # 팀별로 3개 이상 데이터가 존재하는 것을 추출하라!
~~~

### Case study

![zzz](https://user-images.githubusercontent.com/59636424/128469340-0b38de5d-003b-49f4-b9a6-a91899bca3fd.PNG)

: groupby를 통해 month와 item별로 count하여 unstack으로 쌓은 것을 옆으로 늘어놓고 그린 그림

![zzzzzzzzzzzzzzzzz](https://user-images.githubusercontent.com/59636424/128469803-acf8d5b1-0d08-470b-ad98-e078975d4382.PNG)

: ".columns.droplevel(level=0)"을 통해 column 이름이 없어서 어떤 거에 대한 min, max, mean인지 모른다!

=> add_prefix를 통해 어떤 column의 값인지 명시할 수 있다!


### pivot table

: column에 labeling 값을 추가해서 aggregation하는 형태이다!

![zzzzzzzzzzz](https://user-images.githubusercontent.com/59636424/128470194-4040c7bb-69ec-4f86-ac42-8b388b095262.PNG)

=> 가로축에 해당하는 것이 item, 세로축이 network이다!

![gn](https://user-images.githubusercontent.com/59636424/128470313-7adfb4da-4d2b-445b-98c0-9ac731ec32a2.PNG)

-> 값들 안에서 sum으로 계산되고 없는 값은 0을 채운다!!

### crosstab

: 네트워크 형태의 데이터라고 말하며 pivot table의 특수한 형태라고도 한다!

![jpi](https://user-images.githubusercontent.com/59636424/128470808-898f3cb3-4b74-48ee-a705-0e8b2ea77b5d.PNG)


### Merge & Concat


#### merge

: 두 개의 데이터를 어떠한 기준으로 하나로 합침!

* **형태: pd.merge(df_a,df_b,on="컬럼이름")** -> on을 기준으로 합친다!

* **형태1: pd.merge(df_a,df_b,left_on="컬럼이름1",right_on="컬럼이름2")** -> 두 dataframe이 column 이름이 다를 때!

=> how로 inner join, left join 등을 할 수 있다!


#### concat

: list 형태로 값을 붙인다!

-> 옆으로 붙인다! (axis=1으로 설정 시!)

### Database connection

![db연결](https://user-images.githubusercontent.com/59636424/128472574-78c0dd48-a5f5-4942-a5cf-cf5621e77d92.PNG)

: DB 연결 방법!

