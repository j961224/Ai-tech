# 1. 8월 17일 배운 것!

## 1. Introduction to Pytorch

* Pytorch

: Dynamic computation Graph

-> Define and Run(그래프를 먼저 정의 -> 실행시점에 데이터 feed) (TF)

-> Define by Run(실행을 하면서 그래프를 생성하는 방식) (Pytorch)

-> Numpy 구조를 가지는 Tensor 객체로 array 표현

-> 자동 미분을 지원하여 DL 연산을 지원

-> 다양한 형태의 DL을 지원하는 함수와 모델을 지원

## 2. PyTorch Basics

### Tensor

    * 다차원 Arrays를 표현하는 Pytorch 클래스
    
    * numpy의 ndarray와 동일
    
    * Tensor를 생성하는 함수도 거의 동일
    
~~~
np.arange() -> torch.FloatTensor로 사용할 수 있다.

n_array = np.arange(10).reshape(2,5)

t_array = torch.FloatTensor(n_array)
~~~

* Array to Tensor

~~~
data = [[3, 5],[10, 5]]
x_data = torch.tensor(data)
~~~

#### Tensor data types

: 기본적으로 tensor가 가질 수 있는 data 타입은 numpy와 동일

#### numpy like operations

: 기본적으로 pytorch의 대부분의 사용법이 그대로 적용됨

~~~
torch.ones_like -> 1로 도배
~~~

* device로 gpu에 올릴 것인지, 메모리에 올릴 것인지 확인할 수 있다.

~~~
cuda로 gpu 확인!

if torch.cuda.is_available():
    x_data_cuda = x_data.to('cuda')
x_data_cuda.device
~~~

#### Tensor handling


* view: reshape과 동일하게 tensor의 shape을 변환

* squeeze: 차원의 개수가 1인 차원을 삭제 (압축)

* unsqueeze: 차원의 개수가 1인 차원을 추가


![tensor](https://user-images.githubusercontent.com/59636424/129653280-cf08a936-be5f-4fad-82d3-8b5c95180926.PNG)

~~~
tensor_ex = torch.rand(size=(2, 1, 2))
tensor_ex.squeeze()
#tensor([[0.6186, 0.4813],
        [0.2407, 0.4467]])
        
tensor_ex.unsqueeze(1).shape
#torch.Size([1, 2, 2])

tensor_ex.unsqueeze(1).shape
#torch.Size([2, 1, 2])

tensor_ex.unsqueeze(2).shape
#torch.Size([2, 2, 1])
~~~

* 행렬곱셈 연산은 함수는 dot이 아닌 mm을 사용한다.

=> 내적을 구할 때는 dot은 쓰는데 행렬간의 연산은 mm을 쓴다.

![kkk](https://user-images.githubusercontent.com/59636424/129653703-7772c06f-65f9-4ffa-ba32-dffcf6bd4d75.PNG)

* mm과 matmul은 broadcasting 지원 처리

![broadcasting](https://user-images.githubusercontent.com/59636424/129653907-eebfcca3-8143-4bc5-ae71-0a6ac78ce496.PNG)

-> mm은 벡터간의 연산을 지원 안 해주고 broadcasting은 지원을 안 해준다.

-> matmul은 broadcasting을 지원해준다.

#### Tensor operations for ML/DL formula

* nn.functional 모듈을 통해 다양한 수식 변환을 지원한다.

~~~
import torch
import torch.nn.functional as F

torch.cartesian_prod # 모든 경우의 수를 구한다!
~~~

#### AutoGrad

: pytorch의 핵심은 자동 미분을 지원한다. -> backward 함수 사용

* requires_grad를 True로 해주는데 보통 Linear을 사용한다.

~~~
a = torch.tensor([2., 3.], requires_grad=True) # a의 값을 2,3으로 잡음 -> 미분일 경우 값
b = torch.tensor([6., 4.], requires_grad=True) # b의 값을 6,4로 잡음 -> 미분일 경우 값
Q = 3*a**3 - b**2 # 각각 편미분을 해야하므로 값이 2개 나와야한다.
external_grad = torch.tensor([1., 1.]) # external_grad에 관한 크기!
Q.backward(gradient=external_grad) # Q 함수 미분해라!

a.grad #tensor([36., 81.])
b.grad #tensor([-12.,  -8.])
~~~

## 3. Pytorch 프로젝트 구조 이해하기

* OOP + 모듈 -> 프로젝트 단위로 제공이 필요!

* Pytorch Template 추천

https://github.com/victoresque/pytorch-template

### Module 구성

> * 실행
> > 실행할 수 있는 파일 (train.py, test.py)
> * 설정
> * base - abstract module
> > 데이터 부르기, model 구조 설정, trigger.py 저장
> * Data
> > 데이터 저장
> * model
> > model의 성능을 측정하는 metrics과 loss를 측정하는 loss 함수
> * 저장소
> > 중간중간에 모델 저장소, 로그 저장
> * 학습 수행
> > trainers는 학습 수행하는 트리거인데 여러 가지 설정들과 모델들과 데이터 저장소, 로깅 방법을 모두 저장!
> * 로깅 설정
> > 로깅해주는 로거
> * 유틸리티

### git clone으로 가져오기!

![vvvvvvv](https://user-images.githubusercontent.com/59636424/129657036-fb828245-0805-4044-8951-9093fbb28019.PNG)

* mnist를 다운받아서 학습 시키는 것!

![mnist](https://user-images.githubusercontent.com/59636424/129657199-543ddbcc-aef1-486c-b19c-d517381924ed.PNG)

* colab에서 학습 시키는 방법!

~~~
!git clone https://github.com/victoresque/pytorch-template

!ls

%cd /content/pytorch-template 
!python new_project.py MNIST-example #pytorch-template 디렉토리에 mnist-example를 만들어준다! (template들이 그대로 MNIST example에 들어가는 것을 볼 수 있다.)
~~~

* 위의 코드 결과

![bfbfbfbfb](https://user-images.githubusercontent.com/59636424/129657513-efa30bc8-abc6-445e-b590-50a889abf25e.PNG)

~~~
!pip install colab-ssh #computer에 외부에서 ssh로 접속할 수 있도록 하기 위해 설치
launch_ssh(NGROK_TOKEN, PASSWORD) # 이 코드 실행 시, 서버가 돌아간다. -> NGROK_TOKEN은 직접 ngrok에 가입하여 token을 가져와야한다.
~~~

* VS code에서 terminal로 google drive에 파일이 저장될 수 있도록 설정할 수 있다.

#### Pytorch-template 파일 중, train.py 코드 

-> get_logger로 logging을 train level에 한다.

-> init_obj는 object를 불러온다.(mnistdataloader를 attr로 불러오기)

-> model도 같은 방식으로 module_arch를 불러온다!

-> Trainer는 모델을 뭐 넣을지, data를 어떻게 부를지, loss값을 어떤 것을 부를지 설정

(trainer.py에서의 train epoch 함수가 핵심!)

~~~
args.add_argument('-c', '--config', default=None, type=str, help='config file path (default: None)') # 실행 설정 파일을 --config로 부를 수 있다.
args.add_argument('-r', '--resume', default=None, type=str,help='path to latest checkpoint (default: None)') #예전 실행한 것을 연속으로 실행 할 것인가?
args.add_argument('-d', '--device', default=None, type=str,help='indices of GPUs to enable (default: all)') # device는 cpu or tpu 설정 
~~~

* config.json에는 hyper parameter라고 할 수 있는 것들을 설정했다.

* utils.py는 json파일을 읽어 하나의 dict로 바꿔준다.

## 1. 시각화 - Text 사용하기

### 1.1 Anatomy of a Figure

![bfbfbfb](https://user-images.githubusercontent.com/59636424/129666848-fffecc56-77f2-4bc4-9955-f0a762f302c6.PNG)

> * Title: 가장 큰 주제를 설명
> * Label: 축에 해당하는 데이터 정보를 제공
> * Tick Label: 축에 눈금을 사용하여 스케일 정보를 추가
> * Legend: 한 그래프에서 2개 이상의 서로 다른 데이터를 분류하기 위해서 사용하는 보조 정보
> * Annotation(Text): 그 외의 시각화에 대한 설명을 추가

