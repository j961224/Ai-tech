# 1. 8월 13일 공부 내용!

## 9. Generative Models

* Generation: 강아지와 같은 이미지를 만들 수 있다. -> 데이터에 없는 강아지 이미지

* Density estimation: 어떤 이미지가 들어갔을 때, 확률값 하나가 나와서 구분(분류)해내는 것 -> 이상 탐지에 쓰일 수 있다.

(explicity model이라고도 한다. => 입력이 주어졌을 때, 확률값을 얻어낼 수 있는 모델)

* Unsupervied representation learning: feature learning을 할 수 있다. (이미지가 공통적으로 가지는 것을 학습)

### Basic Discrete Distributions

* Bernoulli distribution: 표현하는데 숫자가 1개가 필요하다.

* Categorical dirtribution: m-1개의 파라미터가 필요하다.

* RGB joint distribution은 256 x 256 x 256경우가 있다.

    파라미터는 총 255 x 255 x 255개가 필요하다.
    
    FCN하는데 하나의 픽셀에 대해서 필요한 파라미터가 많다.
    
![dffffff](https://user-images.githubusercontent.com/59636424/129292507-b7676d0e-a255-4408-8ce6-532aadd7ceb7.PNG)

: n개의 binary 픽셀이 있다고 가정하자

-> n개의 필섹이 있다면 2^n - 1의 파라미터 경우의 수가 있다.

* n개의 binary pixel에 n개를 다 쓰지 말고 조금 더 쉽게 하는 방법은?

    n개의 pixel들이 독립적이라고 생각한다면?? -> 가능한 state는 2^n이다.
    
    => distribution을 표현하는데 필요한 파라미터 수는 n개만 있으면 된다. => 각각의 pixel에 대해 n개가 독립적이므로 다 더하면 된다.

### Conditional Independence

* Chain rule: n개의 joint distribution을 n개의 conditional distribution으로 바꾼다.

* Bayes' rule: 이거 역시 exact

* Conditional independence: z가 주어지면 x와 y가 독립적이다.  -> p(x|y,z)=p(x|z)

    이유는 z라는 랜덤 변수를 주어지는 x와 y는 독립적이므로 x라는 랜덤변수 표현 시, z가 주어지면 y는 상관이 없다.
    
    -> conditional 부분을 날려준다. => chain rule가 잘 섞어서 좋은 모델을 만들 수 있다.
    
* chain rule을 사용한다면?

![ch](https://user-images.githubusercontent.com/59636424/129293686-b2aef3d5-8ddd-4d54-bd40-edc6c3c19b57.PNG)

    fully dependent model과 같은 숫자의 파라미터를 갖는 것을 알 수 있다.
    
    -> 이유는 어떠한 가정도 하지 않고 했으므로
    
    p(x1): 1개 파라미터
    
    p(x2|x1): 2개 파라미터 ( p(x2|x1=0)인 확률과 p(x2|x1=1)일 확률이 필요하다. )
    
    p(x3|x1,x2): 4개 파라미터
    
    따라서 2^n - 1개이다.

* Markov assumption을 생각해보자!

: X_i+1은 X_i만 관련 있다고 가정

![ccccc](https://user-images.githubusercontent.com/59636424/129293944-48d52512-a580-4217-be94-18df4c4cfb1a.PNG)

: 차이점은 independent한거를 날려버린다.

=> 2n-1의 파라미터 수가 필요하다. -> exponenetial reduction하다!

=> 이러한 것을 **auto-gegressive model**이라고 한다.

### Auto-regressive Model

![dffffff](https://user-images.githubusercontent.com/59636424/129294099-b02aa269-0c2e-4206-abb4-98d4c41b91ff.PNG)

-> 28 x 28 binary pixel이라고 가정하자!

* 어떻게 표현할까? (p(x)를)

    chain rule을 가지고 나눈다!
    
    ![vvvv](https://user-images.githubusercontent.com/59636424/129294241-05475987-926c-4098-a388-ccd8ba5cc872.PNG)
    
    이러한 방법을 autoregressive model라고 한다.
    
    순서를 다 매겨야한다!
    
    ARN 모델은 이전 정보 N개를 고려하는 것을 말한다.
    
* autoregressive model는 하나의 정보가 이전 정보에 의존한다.


### NADE

![vvvvvvvvvv](https://user-images.githubusercontent.com/59636424/129294791-3fe480b8-7a86-403d-ab9e-2cf2e356ae05.PNG)

: i 번째 pixel을 첫 번째부터 i-1번째 pixel에 의존하도록 한다.

-> neural net 입장에서는 입력 차원이 달라지므로 weight가 계속 커진다!

* explicit 모델로 generation만 하는게 아니라 임의의 784개 주어지면 확률을 계산할 수 있다.

* 어떻게 계산이 가능한가?

    joint 확률을 chain rule로 coditional 분포로 바꾼다.
    
    우리의 모델이 첫 번째 픽셀 확률분포를 알고 있고 이게 주어지면 두 번째 픽셀 확률분포를 알 수 있다.
    
    이렇게 계산을 계속하게 되면 확률값을 구할 수 있다.
    
 => continuous random이라면, Gaussian mixture 모델을 마지막에 활용해 continuous distribution을 만들겠다!
 
### Pixel RNN
 
![kkk](https://user-images.githubusercontent.com/59636424/129295371-16b91611-62e6-48c2-b7b7-7c60b8dd1cf7.PNG)
 
: 이미지에 있는 pixel을 만드는 것이다.
 

-> i번째 픽셀에 R을 먼저 만들고 그 뒤에도 비슷하게 만든다.
 
-> 앞에랑 다르게, RNN를 만든다. => RNN을 통해 generation을 하겠다.
 
#### order을 어떻게 하느냐에 따라 다른 것이 있다!!

![ddd](https://user-images.githubusercontent.com/59636424/129295552-9cb813ea-b3bb-44cf-8bee-2950f4b33cdb.PNG)

##### Row LSTM

: i번째 픽셀을 만들 때 위쪽 정보를 이용한다.

##### Diagonal BiLSTM

: BiLSTM을 활용하되, 이전 정보들을 다 활용하는 것이다.


## 10. Generative Models 2

### Latent Variable Models

#### Variational Auto-encoder

* **Posterior distribution**

![ddd](https://user-images.githubusercontent.com/59636424/129297170-10e12954-bc44-4b46-838d-a6744a6dbc44.PNG)

* posterior distribution(나의 observation이 주어지면 관심 있어하는 random variable 확률분포)을 찾는 것이 중요하다!

* **Variational distribution**

![vvvv](https://user-images.githubusercontent.com/59636424/129297271-751246b2-fd46-4aad-8d05-db28bdd01f1a.PNG)

: 일반적으로 posterior을 하기 힘들어 학습할 수 있는 근사하겠다는 목적이다.

-> 찾고자 하는 posterior distribution 제일 잘 근사할 수 있는 과정이다.

-> KL Divergence를 이용해서 variational과 posterior를 줄여보겠다!!

---

알 수 없는 object와 가깝게 만들어야한다! => Variational은 가능하다.

![cnrgk](https://user-images.githubusercontent.com/59636424/129297766-4e370071-6a4a-4abf-9acb-7807f0069f8c.PNG)

-> KL diverenge로 줄이는 것이 목적인데 불가능하니 ELBO를 계산하여 키움으로써 원하는 object를 얻고자 한다.

-> 모르는 어떤 임의의 posterior distribution과 최적화하려고 하는 variational distribution 거리를 줄이는 목적을 이루고자 한다.

* ELBO

**ELBO를 나눠보자!**

![elbo](https://user-images.githubusercontent.com/59636424/129298261-27cde461-983d-41a0-bf05-0a2389d69ce0.PNG)

궁극적으로 하고자하는 것은 x라는 입력을 잘 표현할 수 있는 z라는 latent space를 찾고자한다.

-> ELBO를 최대화하는 것이 posterior과 vaiartional을 줄여주는 것과 같다. (KL - divergence 줄이기)

-> encoder를 통해서 x라는 입력을 latent space로 보냈다가 다시 decoder로 돌아오는 Reconstruction loss를 줄이는 것이 **reconstruction Term**의 역할이다.

-> 이미지를 latent space올려서 점들이 되는데 그 점들의 분포가 사전 분포와 비슷하게 만들어주는 것과 같은 것이 **Prior Fitting Term**

---

* **한계**

-> VA는 어떤 입력이 주어졌을 때, 얼마나 likely한지 알기 힘들다.

-> KL divergence은 적분이 들어가 있고 intractable하게 되면 개선할 수 없다. -> 그래서 가우시안 prior(isotropic 가우시안)를 사용한다.


#### Adversarial Auto-encoder

![vdvdvdvdv](https://user-images.githubusercontent.com/59636424/129299375-0fd4b3ba-337b-40d9-8aa8-c846cc892112.PNG)

: Variational auto encoder의 단점은 encoder를 활용할 때, prior fitting term이 KL-divergence를 활용하는 것이다. -> 가우시안이 아니면 사용이 힘들다.

-> 그거를 위해 Adversarial auto-encoder는 variational의 prior fitting term를 gan objective로 바꿔버린다.

-> **복잡한 다양한 분포를 latent distribution으로 활용이 가능한 것이 큰 장점이다.**


### GAN

![v_v](https://user-images.githubusercontent.com/59636424/129299929-61485ec4-0ae6-419e-aef6-700095ed2765.PNG)

: 속임을 당하는 D는 generator는 더 잘 속이려고 하는 방식으로 반복하여 궁극적으로 generator 성능을 높이려고 한다.

-> **학습의 결과로 나오는 generator를 학습하는 discriminator가 점차 좋아진다.** -> 이것으로 generator가 좋아진다.


### Variational Autoencoder vs Generative Adversarial Network

![zzz](https://user-images.githubusercontent.com/59636424/129300021-7dbccfc7-8810-4859-9546-841cd81622fa.PNG)

: 왼쪽은 아래에서 위로! (위에서 2번째가 decoder 단계로 generation 단계이다.)

-> GAN은 z에서 출발해서 D는 가짜와 진짜를 구분을 학습한다. -> G는 그렇게 학습된 D 입장에서 True가 나오도록 다시 G를 업데이트하고 D는 결과로 나온 이미지들이 real image와 구별하도록 하는 어떤 D를 다시 학습한다.

### GAN Objective

: 한 쪽은 높이고 싶어하고 한 쪽은 낮추고 싶어한다.

* 항상 최적화시키는 discriminator

![zzzzzzzzzzzzzzzzzzzzzzz](https://user-images.githubusercontent.com/59636424/129300449-fd935e59-179a-4ef2-b9fc-aa9e3e5de5d5.PNG)

: generator가 fixed가 되면 항상 최적으로 갈라주는 optimal discriminator(높으면 True, 낮으면 False)이다.

![zsssssssssss](https://user-images.githubusercontent.com/59636424/129300754-9422c6f1-aed3-43eb-9668-58d1d7a9dd9a.PNG)

-> GAN object가 많으면 데이터가 실제 만들었다고 생각하는 distribution과 내가 학습한 generator 사이의 JSD를 최소화하는 것이다.

### DCGAN

![aa](https://user-images.githubusercontent.com/59636424/129301156-822e0447-cafb-4a8d-96d1-b2408f4aebd6.PNG)

: 이미지 도메인으로 한 것이다.

-> 이미지 만들 때는 deconvolution layer를 받게 generator를 만드는 것이 좋다.

### Info-GAN

![vvvv](https://user-images.githubusercontent.com/59636424/129301504-8a7b401f-3ca9-4c82-9dd9-7cf39fac7c89.PNG)

: 학습을 할 때, class라는 c라는 것도 랜덤하게 집어넣어 학습시킨다. -> generation 할 때, gan이 특정(c라는 것으로 나오는 원핫벡터) 모두에 집중할 수 있게 한다.

### Text2Image

![textimage](https://user-images.githubusercontent.com/59636424/129301573-4c9b68b7-cd70-4d68-8466-e509cc116c70.PNG)

: 문장이 주어지면 이미지를 만든다.

### Puzzle-GAN

![vvvvvvvv](https://user-images.githubusercontent.com/59636424/129301805-0a93debf-58db-41cb-be7f-76107624d818.PNG)

: 이미지 안에 subpatch(자동차라면 바퀴 등)들이 들어가면 원래 이미지 복원하는 것

### CycleGAN

: GAN구조를 활용하지만 이미지 사이의 2개 도메인을 바꿀 수 있다.

#### Cycle-consistency loss

![zczc](https://user-images.githubusercontent.com/59636424/129301904-dd104610-06c0-43f1-a858-cc76a60d808e.PNG)

: 2개의 똑같은 이미지의 사진이 필요한데 그럴 필요없다. -> 알아서 임의의 말 이미지를 주어지면 얼룩말 이미지로 바꿔준다.

-> GAN 구조가 2개 들어간다.


# 2. 피어세션 정리

---

1. 잘했던 점
    * 1) 조금 더 적극적인 태도
    * 2) 모르는 것이라도 자료 조사 적극적으로 하고 알아보기
3. 부족했던 점
    * 1) 피어세션 때 조금 더 내용 , 기술적인 면 관련해서 토의해보기
    * 2) 논문 리뷰 및 Pytorch 중심으로 얘기 나누어보기
5. 도전할 것 
    * 1) 과제를 정해진 기간에 마치고 다음 날에 서로 의견 나누기 - 어려웠던 점 , 몰랐던 점, 새로 알게된 점
    * 2) 시간 여유가 되는 사람은 논문 분석 및 구현하고 Slack에  올려보기
7. 좋았던 점
    * 1) 모호하게 알게 되는 점을 서로 알게되고 공유하면서 확실하게 알게 됨
  
멘토님께 질문하기
  1. 논문 읽는 방법
  2. 논문 선정 방법
  3. 논문 공부 방법
  4. 추천하는 책?
  5. 스타트업과 대기업의 회사 문화 및 실무 차이
