# 1. 8월 12일 배운 내용!

## 1-1. RNN

### Sequential Model

: 과거 고려해야하는 정보량이 늘어난다!

* Autoregressive model

![ㅊㅊㅊ](https://user-images.githubusercontent.com/59636424/129120488-cfe9ecb0-0179-490c-a227-31eb180c026e.PNG)

=> 과거의 몇개만 보는 방법이 있다.

* Markov model(first order autoregressive mode)

![ㅇㄹㅇㄹ](https://user-images.githubusercontent.com/59636424/129120588-b73c06b1-b10c-42a5-9cd5-435ad02b92cf.PNG)

: 내가 가정하기에는 바로 전 과거에만 현재가 의존한다.

-> 많은 정보를 버리게 되지만 joint distribution 표현하기에 쉽다.

* Latent autoregressive model

![ㅍㅍㅍㅍㅍㅍㅍㅍㅍㅍㅍ](https://user-images.githubusercontent.com/59636424/129120694-50061f9d-24c2-4568-9d27-c94107b06676.PNG)

: 중간에 히든 state가 과거 정보를 요약하고 있다. -> 과거 이전에 정보를 요약하고 있다.

### RNN

![ㅇㄹㅇㄹㅇㄹ](https://user-images.githubusercontent.com/59636424/129120855-31c1ce58-46e2-48e4-9183-30ab7ab842ff.PNG)

: 자기 자신으로 돌아오는 구조가 더해져 있다. (hidden state time stamp는 Xt에만 의존하는 것이 아니라 이전에 t-1에도 의존한다.)


![ㅊㅊㅊㅊㅊㅊㅊㅊ](https://user-images.githubusercontent.com/59636424/129120992-64989234-68a5-4b52-9db3-2ee2a41ba90c.PNG)

: 시간 순으로 풀면 각각의 네트워크의 파라미터를 shared 한다.

* **RNN의 단점**

![ㅔㅔ](https://user-images.githubusercontent.com/59636424/129121226-e824a5f2-0915-4395-b464-f638e8d8a46e.PNG)

: RNN의 단점으로 long term dependency로 과거의 정보를 취합해서 미래에서 고려해야하는데 하나의 fixed rule로 계속 정보를 취합하기에 과거 정보가 미래까지 살아남기가 힘들다.


* RNN의 학습 원리

![ㅣㄴ](https://user-images.githubusercontent.com/59636424/129121337-ed465c92-f323-452f-828b-f57be64b9eee.PNG)

: 중첩되는 구조로 activation 함수로 줄여버리면 점점 과거의 정보가 줄어들다 결국 long term dependency가 일어난다. -> gradient 손실


### LSTM

![ㅣㄴ스](https://user-images.githubusercontent.com/59636424/129121406-fd282252-b89c-4f6c-bf19-c21642b4345d.PNG)

(LSTM의 구조)

![ㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊ](https://user-images.githubusercontent.com/59636424/129121813-8007dfdf-fd37-415e-8e07-cdb4b98ab822.PNG)

-> x는 입력으로 단어이다.

-> previous cell state는 내부에서만 흘러가고 지금까지의 정보를 취합한 것이다.

-> output은 다음 번에 previous hidden state로 들어간다.

    * forget gate
    
    * input gate
    
    * output gate
    
---

* Core idea

: **cell state**가 핵심이다!

-> 매번 t마다 정보가 올라오면 정보를 조작해 어떠한 정보가 유용함에 따라 조작해 넘겨준다. (gate 이다.)

---

#### Forget gate

![forget](https://user-images.githubusercontent.com/59636424/129121997-06cc084c-28cb-43dd-8499-e18e0560c49a.PNG)

: 어떤 것을 버릴지 선정

#### Input Gate

![input](https://user-images.githubusercontent.com/59636424/129122315-92d95c80-3a38-4217-8fa8-560d6c391ec5.PNG)

: 현재 입력이 들어오면 무작정 올리는 것이 아니라 어떠한 정보를 올릴지 결정

-> i_t는 이전의 previous hidden state와 현재 입력을 가지고 만든다. (어떤 정보를 올릴지/추가할지)

-> cell state candidate는 이전의 cell state와 현재 입력으로 다른 학습 neural net으로 tanh로 정규화 시킨 값 (올릴 정보를 알아야 하는데 그 역할)

#### Update cell

![vf](https://user-images.githubusercontent.com/59636424/129122527-417d09c1-504f-4abc-9a28-ff8f9190473d.PNG)

: cell state를 업데이트 시킨다.

=> 버릴 것은 버리고 가져갈 것은 가져간다.

#### Output gate

![output](https://user-images.githubusercontent.com/59636424/129122557-c5cd8b28-3103-4b6f-b001-8e372afbcce7.PNG)

: 어떤 값을 밖으로 내보낼지 결정한다.


### GRU

![gru](https://user-images.githubusercontent.com/59636424/129122853-5020fd5a-7b27-43c0-b551-f4f701ac3bd8.PNG)

-> cell state가 없고 reset gate와 update가 있다. => 오직 hidden state밖에 없다.


## 8. Sequential Models - Transformer

* Sequential model이 어려운 이유?

![중간](https://user-images.githubusercontent.com/59636424/129129009-9b82ef13-f872-4b24-8a69-3d723a0c7f01.PNG)


      완벽한 대응 구조를 만들지 않기 때문이다.-> 중간에 정보가 빠지거나 뒤바뀌는 것 때문에도 어렵다.
      
      -> 이것을 해결하기 위한 것이 Transformer
      
      
### Transformer

![transfomer](https://user-images.githubusercontent.com/59636424/129129120-2ac2f7d6-04eb-4e9b-a991-d1bff43eff6d.PNG)

: 재귀적 구조가 없고 **attention이라고 불리는 구조를 사용했다.**

=> sequential한 데이터를 처리하고 encoding하는 방법이다. (이미지 분류, detection에도 사용)

![seq2](https://user-images.githubusercontent.com/59636424/129129740-bc9e6507-6763-4604-8aba-eaccbbdbace0.PNG)

* 어떤 다른 언어를 번역하는 것은 seq2seq라고 한다.

![ttt](https://user-images.githubusercontent.com/59636424/129130341-e2843ac3-28e7-41b6-8440-cf4a3d71a96a.PNG)

      입력은 3개의 단어로 되어 있고 출력은 4개의 단어로 되어 있는데 입력 sequence와 출력 sequence는 단어 숫자가 다를 수 있고 각 도메인도 다를 수 있다.
      
      RNN은 3개의 단어면 3번 RNN돌아가지만 transfomer encoder는 몇 개 단어가 들어가든 1번 돌아간다. => 물론 generation은 한 단어씩 만든다.
      
      동일한 구조를 갖지만 네트워크 파라미터 학습이 다르게 된다.
      
      
=> **어떻게 N개의 단어가 1번 돌아가고 어떻게 encoder와 decoder가 정보를 주고 받는지도 중요하다.**

---

### self-attention

![fefdfdfdf](https://user-images.githubusercontent.com/59636424/129130479-1cd6c369-1182-474b-8aac-5f285ac7c932.PNG)


우선, n개의 단어가 encoder에 들어간다.

* **self attention**이 encoder와 decoder를 잘 되게 도와준다.

* Transformer는 어떤 것을 해주는가?

![vvfvfvf](https://user-images.githubusercontent.com/59636424/129130761-620a3676-c4b0-4dea-ad61-d12f34d51965.PNG)

      3개의 단어를 3개의 vector를 찾아준다.
      
      self attention은 vector에서 vector로 가는 것이 x1 정보만이 아닌 x2, x3정보도 활용한다. -> z1을 찾기 위해서
      
      feed forward network는 dependency가 없다. -> 1번 변환만 시행

* **self attention은 하나 문장에 다른 단어와 interaction이 아는 것이 중요하다!**

![ccccccc](https://user-images.githubusercontent.com/59636424/129131038-05ae484b-e68d-41fb-9660-ee27d0888518.PNG)

      다른 단어와의 관계성이 중요한데 알아서 학습이 된다.
      
      3가지의 벡터를 만들어낸다!! => Query, Keys, Values!
 
![score vector](https://user-images.githubusercontent.com/59636424/129131267-66818aa4-102e-433a-886f-89610b964e37.PNG)
      
      1. 이 벡터들로 Score vector를 만든다. (i번째의 단어를 계산할 때, 내가 encoding하고자하는 벡터의 query vector와 나머지 n개의 key vector를 구해 내적을 한다)
      
      => 이 두 벡터와 연관이 있는지 보고 i번째 단어가 나머지 n개의 단어와 관계가 있는지 정함!
      
      => 이것을 알아서 하도록 함 => attention!

![vvvv](https://user-images.githubusercontent.com/59636424/129131476-da8a9f9b-039d-42ae-8338-88b2ea9ff5ff.PNG)

      2. score 벡터를 normalize해주는데 여기서는 8로 나눈다. (8은 key vector 차원과 관련 있다)
      
      => 값 자체가 크게 되지 않도록 한다.
      
      3. softmax를 취하게 되면 자기 자신에 대한 attention에 대한 값이 나온다.
 
![ererrer](https://user-images.githubusercontent.com/59636424/129131802-9d50e36b-8a73-4686-a250-034b528a9b93.PNG) 
 
      4. 각각의 단어에서 나오는 value weight sum이 된다. 
      
      => value vector들의 weight를 구하는 것이 목표이다!!
      
      
 앞의 과정들로 하나의 단어의 encoding vector를 구할 수 있게 된다!  
 
 * **주의할 점!!**

      1. Query vector와 key vector는 차원이 같아야한다. => 내적하므로 => value vector는 달라도 된다.

      2. encoding vector의 차원은 value vector 차원과 같다 => multi attetion은 다르다.


* 최종 encoder 과정

![softmaxdd](https://user-images.githubusercontent.com/59636424/129132443-167b3b1f-05da-4c5a-9afc-0e1a94ab7990.PNG)

* **왜 이 과정이 잘 될까?**

우선, input이 fixed 되어 있으면 출력이 multi neural net이나 CNN으로 차원을 바꿔도 output도 고정된다. => operation으로 나오는 convolution filter나 weight가 고정되어 있기 때문이다.

=> Transformer는 한 개 input이 고정되어 있어도 encoding하려는 단어와 옆에 있는 단어에 따라 encoding 값이 달라진다.

=> Transformer는 n개의 단어가 주어지면 n x n attention map을 만들어야한다. => 단어 1000개를 처리하면 1000 x 1000 입력을 처리해야한다.

=> RNN은 1000개 sequence가 주어지면 1000번 돌린다.

**따라서, transformer는 n개의 단어를 1번에 처리해야하므로 length가 길어지면 처리 한계가 있다.**

### Multi-headed attetion(MHA)

![ererrer](https://user-images.githubusercontent.com/59636424/129133883-75537856-6dc6-4ea3-8626-a055ac3221f1.PNG)

: attention을 여러번 하는 것이다. => 하나의 입력에 대해서 query, key, value를 여러 개 만든다.

=> n개의 attention을 반복하면, n개의 encoding된 vector가 나온다.

=> **고려할 점은,** 입력과 출력의 차원을 맞춰줘야 한다!!

![rererereer](https://user-images.githubusercontent.com/59636424/129133962-de6ea094-f8f8-4391-b738-e30d715b3f52.PNG)

: learnable linear map으로 10 차원이었고 8개의 단어였으므로 80차원 encoding vector라고 볼 수 있으므로 80 x 10 행렬을 곱해 10차원으로 줄인다는 말이다!

---

* **Multi-headed attetion 전반적 과정**

![과정](https://user-images.githubusercontent.com/59636424/129134121-5180338a-31b5-48a6-a03a-ba963d5be4ee.PNG)

      1. input이 들어오면 각각의 단어를 임베딩한다.
      
      2. 8개의 self-attention으로 8개의 encoding vector를 만들어 다시 원래 dimension을 줄여주는 linear map을 찾아 차원을 맞춰준다.
      
      => 사실은 이렇게 구현되어 있지 않다. => 100차원에 8개 head를 사용하면 100차원을 10개로 나눈다. (실제로 query, key, value를 만드는 것은 10차원 입력만 가지고 만들게 된다)

#### positional encoding

![쟂](https://user-images.githubusercontent.com/59636424/129134676-8c63c6ec-7556-48f5-80a1-7a1ecaf6016c.PNG)

: 입력에 특정 값을 더해주는 것이다. (bias 느낌)

=> 왜 필요하냐면 transfer구조는 n개의 단어를 sequential하게 넣어줬다면 하지만 sequential한 정보가 안에 포함되어 있지가 않다.

(self attetion을 생각하면 order에 독립적이므로 문장을 만들 때 어떤 단어의 순서가 중요한데 position encoding이 필요하다)


### 전반적인 self-attetion과 Multi-headed attetion 구조

![ㄷㄱㄷㄹ](https://user-images.githubusercontent.com/59636424/129134830-47d507ec-5954-4e86-ae4d-9e04e5af06b7.PNG)

### Decoder

Transformer는 결국 Key와 Value를 보낸다. 

![ㅇㄹㄹㄹ](https://user-images.githubusercontent.com/59636424/129135127-9209f234-84eb-4ab5-9168-93e3e944aef9.PNG)

      이유는 i번째 단어를 만들 때, query vector와 key vector로 attention을 만들고 weight sum을 했다.
      
      input에 있는 단어를 decoder에 있는 단어에 대해 attention map을 만들기 위해서 input에 해당하는 key와 value가 필요하다.
      
      단순히, 가장 상위 layer에 단어들을 만든다.


최종 출력은 autoregressive한 방법을 쓴다. (한 단어씩 만들어낸다.)

* 학습단계에서 masking을 한다. => 이전 단어들만 연관있고 뒤에 있는 단어들은 연관 없게 만든다. => 미래의 정보를 쓰지 않도록 하겠다. 

#### Encoder-Decoder Attention

![ㅇㄹㅇㄹㅇㄹㅇㄹㅇㄹㅇㄹ](https://user-images.githubusercontent.com/59636424/129135491-c8bdab4b-c4c5-4364-b8e8-29181661d4f0.PNG)

: encoder와 decoder와의 관계로 이전까지 generation한 단어들로 query를 만들고 key, value는 encoder들에 주어지는 encoded vector를 사용한다.

#### Final layer

![단어 생성](https://user-images.githubusercontent.com/59636424/129135571-30d928f3-9c79-4da8-8834-93f3ff1d0358.PNG)

: 단어들의 분포를 만들어서 매번 샘플링하는 식으로 돌아간다.

### Vision Transformer

![ㅏㅏㅏ](https://user-images.githubusercontent.com/59636424/129135841-501650b5-7df5-45bf-97f9-897e72811706.PNG)

: encoder만 활용하여 encoder에서 나오는 첫번째 encoded vector를 분류기에 넣어 이미지 분류를 한다.

=> 원래는 문장들이 주어지는 것을 이미지에 맞게 이미지를 특정 영역으로 나눠 각 영역의 subpatch들을 linear layer를 통과해 하나의 입력으로 사용

=> positional embedding이 들어간다.
      

### DALL-E

![ㅇㄹㄹㅇㄹㄹㅇㄹㄹㄹㄹㄹ](https://user-images.githubusercontent.com/59636424/129135972-11c94098-8b6d-48d8-94b0-3cd0fd79f2af.PNG)

: avocado라는 armchair라는 문장으로 알아서 generation된 이미지이다.

=> Transformer의 decoder만 이용했다.


# 3. 과제 수행 과정 / 결과물 정리

## Pytorch로 구현한 LSTM

### Model 정의

#### __init__ 함수

: LSTM은 cell state 차원과 output 차원이 같아야한다. 그리고 layer가 몇 개인지를 정의하고 batch_first로 lstm output이 어떻게 나올지 설정한다.

-> output에 우선 linear layer를 미리 하나 만들었다.

#### forward 함수

: hidden state와 cell state를 먼저 초기화하는데 입력 차원과 히든 차원이 같아야 하므로 입력 size와 히든 차원과 layer 수를 넣어 초기화한다.

그리고 입력값과 hidden과 cell state를 rnn에 넣어주고 output으로 rnn에 넣은 값을 linear layer에 넣어 view로 차원을 output 차원으로 변경해준다.

그래서 rnn을 출력값의 사이즈는 LSTM feature 차원에 sequence 길이와 batch 수의 사이즈를 가진다. (batch 사이즈 x sequence 길이 x LSTM feature 차원)

Hidden과 cell state의 차원은 LSTM feature 차원과 함께 batch의 수와 layer 수로 사이즈가 이뤄져 있다. (layer 수 x batch 수 x LSTM feature 차원)

* **RNN, LSTM 파라미터가 많은 경우가 있다.** => input gate, output gate 등은 Dense layer이므로 -> hidden 차원을 줄이는 것이 중요하다!


### 결과

![결과](https://user-images.githubusercontent.com/59636424/129127778-0e878301-7659-4497-a93c-5b57984c7dd5.PNG)

이미지라서 28 x 28 input이라 1줄씩 받아서 사용한다. 그래서 이미지라도 LSTM이 잘 나오는 이유는 앞에서 1줄씩 본 정보를 잘 취합해서 본다는 것을 알 수 있다.






