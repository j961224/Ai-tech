# 1. 8월 11일 배운 것!

## 4. Convolution이란?!

![convo](https://user-images.githubusercontent.com/59636424/128952568-936700aa-49b2-4e84-b87a-a7d02f7578bc.PNG)

마지막 수식에서, I는 전체 이미지 공간이고 K는 적용하고자 하는 convolution filter이다!

![convolution계산](https://user-images.githubusercontent.com/59636424/128952902-1620dc94-8582-4072-ab4d-3fd0163d8e04.PNG)
(Convolution 계산법)

* **2D Convolution한다는 것은?!**

![ㅊㅊㅊㅊ](https://user-images.githubusercontent.com/59636424/128953029-a006323b-1ac9-4bd8-8f3f-f1dca0e51c24.PNG)

: 해당 Convolution filter모양을 해당 이미지에 찍는다!

=> 적용 filter 모양에 따라 Convolution output이 위에 3개가 된다!

* RGB Image Convolution

![채ㅜㅊㅊ](https://user-images.githubusercontent.com/59636424/128953545-31364be4-15f9-47ca-b1ef-b3db86d1906c.PNG)

: filter 크기는 항상 같다! => 5 x 5 filter를 한다는 말은 5 x 5 x 3 filter/kernel을 사용한다는 말이다!

* Convolution filter channel 갯수에 맞게 output도 똑같은 갯수로 나온다!

![ㅇㅇㅇㅇㅇㅇㅇㅇㅇㅇㅇㅇㅇㅇㅇㅇ](https://user-images.githubusercontent.com/59636424/128953999-061592da-6448-4cce-8d1a-aa9787caa13c.PNG)

: 1번 Convolution을 거치고 나면 nonlinear acitvation이 들어가게 된다. => 여기서는 Relu가 들어간다. (4개 convolution filter가 필요)

---

### Convolution Neural Networks

![좀ㅅ소](https://user-images.githubusercontent.com/59636424/128954229-a0ca8a7c-1bf8-48be-b31d-ff01367ff83e.PNG)

* convolution layer: counvolution filter로 훑어서 값을 얻어내는 것 (feature extraction)

* polling layer: average polling 등 (feature extraction)

* fully connected layer: 마지막에 다 합쳐서 최종적 결과값을 내는 것 (decision making) => 요새 최소화나 없애는 추세!

* **fully connected layer를 왜 없애는 추세인가?**

: 내가 학습시키고자 하는 파라미터 숫자가 늘어나면 학습이 어렵고 generalization performance(학습에서 얻어진 결과가 다른 테스트 데이터가 얼마나 동작할지)가 떨어진다!

### Stride

![ㄴㅅ걍ㄷ](https://user-images.githubusercontent.com/59636424/128954727-dcd60d24-45c9-4f23-8a6f-c96b532806d5.PNG)

: convolution filter를 얼마나 자주 찍을지를 말함

### Padding

![ㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊㅊ](https://user-images.githubusercontent.com/59636424/128954915-20464cf8-d5ec-4146-b86d-51b567148b26.PNG)

: zero padding을 하게 되면 위의 그림과 같이 spacial demension이 같아진다!

### Convolution Arithmetic

![계산](https://user-images.githubusercontent.com/59636424/128955189-1cc189b9-64cf-42a5-935e-e39e6cdf2502.PNG)

-> channel 64이므로 convolution filter가 64개 필요하므로 3 x 3 x 128 x 64이다.

![믿ㅌ둣 게산](https://user-images.githubusercontent.com/59636424/128955490-d022ad4f-0a1c-4e09-8612-5e72cc488ba9.PNG)

-> 2가 곱해진 이유는 96 channel짜리 filter map을 만들어야하는데 gpu 메모리가 크지 않아서 맞추기 위해 48짜리를 2개 만들었다.

![좀ㅅ'](https://user-images.githubusercontent.com/59636424/128956834-1e57932d-b7f4-4b22-a393-9a4fe6eab388.PNG)

* Dense layer(fully connected layer) 차원은 input 파라미터 개수(neural net 개수)와 output neural net 개수를 곱한 것 만큼이다.

* Dense layer 파라미터 개수가 convolution layer에 비해 엄청 많다.

    * 왜?: convolution operator가 각각의 하나의 커널이 모든 위치에 대해서 동일하게 적용되기 때문이다.

    * convolution operator는 shared parameter이다.
    
    * 그래서 파라미터를 줄이기 위해, fully connected layer를 줄이려고 한다.

~~~
첫 번째 layer는 입력 이미지는 244 x 244이다!
한 개의 kernel은 11 x 11 x 3이다.


두 번째 layer는 전의 kernel size는 5 x 5 x 48 kernel size이고 channel은 128로 늘었으므로 5 x 5 x 48 x 128 * 2 파라미터 개수를 가지고 있다.

세 번째 layer는 전의 kernel size는 3 x 3 x 128 kernel size가 2개이고 channel은 192이므로 3 x 3 x 128 x 2 x 192 x 2 파라미터 개수를 가지고 있다.

네 번째 layer는 전의 kernel size는 3 x 3 x 192 kernel size이고 channel은 192이므로 3 x 3 x 192 x 192 x 2 파라미터 개수를 가지고 있다.

마지막 layer는 전의 kernel size는 3 x 3 x 192 kernel size이고 channel은 128이므로 3 x 3 x 192 x 128 x 2 파라미터 개수를 가지고 있다.

첫 번째 Dense layer은 전의 kernel size는 13 x 13 x 128 kernel size이고 channel은 2048 이므로 13 x 13 x 128 x 2 x 2048 x 2 파라미터 개수를 가지고 있다.

두 번째 Dense layer는 input 파라미터 개수인 2048 x 2 와 현재 channel은 2048 size이므로 2048 x 2 x 2048 x 2 파라미터 개수를 가지고 있다.

마지막은 2048 x 2 input 파라미터 개수와 channel size는 1000이므로 2048 x 2 x 1000 파라미터 개수를 가지고 있다.
~~~

### 1 x 1 convolution

![ㅋㅋㅋㅋㅋㅋㅋㅋ](https://user-images.githubusercontent.com/59636424/128957031-15333341-a9c6-4cca-a097-9d6b4bdc7fae.PNG)

: 한 픽셀만 보는 것이고 channel 방향으로 줄인다.

=> 차원 줄이기 위해서 사용한다!

    * 1 x 1 convolution context dimension은 channel을 말한다.
    
    * convolution layer를 깊게 쌓으면서 파라미터 숫자를 줄일 수 있다. => bottleneck architecture이다!


