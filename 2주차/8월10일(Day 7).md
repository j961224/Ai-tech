# 1. 8월 10일 배운 내용!

## 3. Optimization

### Gradient Descent

: 미분으로 local minimum을 찾으며 최적화시킨다.

![zzzzzzzzzzzzz](https://user-images.githubusercontent.com/59636424/128792514-57c92266-a9c0-4e1c-a54d-1ddf14c29a8b.PNG)


### Important Concepts in Optimization

#### Generalization

: training error와 test error 사이의 차이를 generalization gap이라고 한다.

##### Underfitting

: 네트워크가 너무 간단하거나 그럴 때, 학습 데이터도 못 맞추는 경우이다.

##### Overfitting

: 학습 데이터에는 잘 적용하지만 test 데이터에 대해서 잘 적용되지 않는다.


##### Cross-validation

: 학습 데이터로 학습시킨 모델이 학습에 사용되지 않는 validation 데이터로 얼마나 잘 되었는지 보는 것!

* k-fold cv

![cross](https://user-images.githubusercontent.com/59636424/128793024-235fa0bd-4ac0-48f6-9074-4cba56c6e9db.PNG)

: k개만큼 나누는 것을 의미한다!


##### Bias and Variance

: Bias는 같은 곳에 얼마나 찍히는지를 말하는 것이고 Variance는 출력이 얼마나 일관적으로 나오는지를 말한다.

##### Bias and Variance Tradeoff

: 학습 데이터에 noise가 껴 있을 때, noise가 껴 있는 target data를 최소화하는 것은 bias^2, variance, noise이다.

=> 최소화하는 것은 하나인데 3개가 엮여 있어 다른 것이 커질 수 있다.

![biasnoise](https://user-images.githubusercontent.com/59636424/128793483-cf35757c-33fd-4b8a-8131-b4464faf0276.PNG)

=> variance를 줄이는데 bias가 높아질 가능성이 높다.

=> 학습데이터에 noise가 있을 경우, bias와 variance 둘 다, 줄이기는 힘들다.

##### Bootstrapping

: 학습 데이터가 100개 있다면, 몇 개만 활용한다. -> 80개씩 뽑아서 모델 만들고 또 다른 모델을 만드는 등의 여러 모델을 만들 수 있다.

-> 모델의 예측 값들이 얼마나 일치를 이루는지 볼 수 있다. -> 학습 데이터가 고정되어 있을 때, subsampling으로 학습 데이터를 여러 개 만들어 여러 모델을 만들어서 한다.

~~~
데이터 셋 내의 데이터 분포가 고르지 않은 경우를 말하고 overfitting을 줄이는 데 도움이 된다.
~~~

##### Bagging vs Boosting

###### Bagging(Bootstrapping aggregating)

: 배깅은 샘플을 여러 번 뽑아(Bootstrap) 각 모델을 학습시켜 결과물을 집계(Aggregration)하는 방법이다.

-> 학습 데이터가 고정 되어 있을 때, 학습데이터 여러개 만드는 경우 -> random subsampling을 통해 만들어 여러 모델의 output을 평균 내는 것

-> 대표적인 활용 모델이 random forest이다.

###### Boosting

: 학습 데이터가 있다면, 이 중 sequencial로 바라보고 모델의 간단한 것을 만들어 학습데이터에 대해서 돌린다.

-> test data 예측을 못 할 때, test data를 가지고 다른 모델을 만들어 이거만 잘 예측하는 것을 만든다.

=> 이러한 모델들을 합친다. -> sequencial하게 합쳐서 하나의 강한 모델을 만든다.

![zzzzzzzzzzzzzzzzzz](https://user-images.githubusercontent.com/59636424/128794883-8adb1dbe-10d5-40ed-bf0d-147fd849e00b.PNG)


### Gradient Descent Methods

##### Stochastic gradient descent

: 10만 개 중에, 1개만의 gradient를 얻어 또 한개를 얻어 gradient를 얻어 업데이트를 한다.

#### Mini-batch gradient descent

: 10만 개를 다 사용하지도 않고 1개만도 사용하지 않는 일반적인 batch size만큼 활용하여 하나의 gradient를 구해 업데이트를 반복한다.

#### Batch gradient descent

: 10만 개를 다 사용하여 10만 개 모든 gradient 평균을 구한다.

#### Batch-size Matters

-> batch size를 작게 쓰는데 일반적으로 성능이 좋다! (flat minimize에 도착하는 것이 좋다.)

![z_z_z](https://user-images.githubusercontent.com/59636424/128795532-61621726-4f65-45fe-842c-1d43b5f89db4.PNG)

-> sharp minimun에 도달하면 testing function에만 약간 떨어져도 있어도 testing function은 높은 값이다.

==> train단계에서 얻은 값들이 test data 기준으로 잘 동작을 안 할 수 있다.

---

#### Gradient Descent(Stochastic)

![dd](https://user-images.githubusercontent.com/59636424/128795949-283295c3-34a4-4991-9e94-afa37d5107e5.PNG)

-> 문제는 learning rate를 잡는데 어렵다!

#### Momentum

-> Gradient Descent를 보완한 것

![momentum](https://user-images.githubusercontent.com/59636424/128796375-809802ff-2cad-4a2f-9880-5cfd8ff9e859.PNG)

: 베타라고 불리는 하이퍼파라미터가 들어간다. (momentum)

=> g라고 불리는 gradient가 현재 들어오면 다음 번에 gradient를 버리고 a라고 불리는 momentum에 해당하는 term이 그 값을 들고 있다.

=> 한 번 흘러가기 시작하면, 어느 정도 유지시켜준다.

#### Nesterov Accelerate Gradient

: gradient 계산 시, Lookahead gradient를 계산한다.

![nag0](https://user-images.githubusercontent.com/59636424/128796944-0492f1bf-ca85-48f8-9b46-fb25b1f6852a.PNG)

한 번 이동하는데 a라고 불리는 현재 정보가 있다면 그 방향으로 가보고 간 곳에서 gradient를 계산한 것으로 accumulate한다.

~~~
세타 - 감마 x v_(t-1)은 파라미터의 다음 포지션의 대략적인 값을 준다. (그 기울기는 전체 업데이트에서 잃어 버린다)
또한 우리의 파라미터들이 어디에 있을 것인지에 대한 대략적인 정보를 준다. (이것은 우리가 곧 끝날 곳 근처의 지점이다)

우리의 파라미터의 대략적인 미래의 포지션에 의한 기울기를 계산함으로써 미리 볼 수 있다.
~~~

![nag1](https://user-images.githubusercontent.com/59636424/128796945-c5106133-fdff-499d-ad41-ede96c4e42fc.PNG)

-> local minimum가 수렴 못하는 상황이 발생한다. (Momentum update)

-> NAG는 1번 지나간 그 점에서 gradient를 계산하므로 local minimum가 한 쪽으로 흘러간다. -> **빠르게 수렴한다!**

-> **모멘텀 스텝에 의해서 움직인 상태에서의 기울기 상태를 계산하여 이동을 하는 것**

~~~
- 기존 모멘텀 

: 기울기 업데이트는 첫 번째로 적용되고, 그러고 나서, 모멘텀 방향으로 점프하는 것이 뒤 따른다.

-> 기울기 스텝과 모멘텀 스텝의 합으로 실제 스텝이 업데이트


- NAG

: Nesterov는 모멘텀 방향으로 먼저 점프를 하고, 이 방향을 기울기 업데이트와 함께 수정하는 것이 더욱 좋다는 것을 보였다.

-> 사전에 보는 기울기 스텝(기존의 것과 조금 다르다)을 통해서 실제 스텝을 계산
~~~

#### Adagrad

: 뉴럴 넷의 파라미터가 얼마나 변해왔는지를 본다.

-> 파리미터가 많이 변한 파라미터는 적게 변화시키고 조금만 변화한 것은 많이 변화시킨다!

![adagrad](https://user-images.githubusercontent.com/59636424/128798545-549e86d0-0d65-4258-8f77-b14d2a75cbf1.PNG)

-> 각 파라미터가 얼마나 변화했는지를 저장하는 부분이 G이다. -> 계속 커진다!(파라미터가 계속 변했다는 증거!)

-> G를 역수로 넣어 위와 같이 변화시킨다!

-> 뒤로 가면 갈수록 G가 계속 커지니 G가 무한대로 가게되면 업데이트가 안 된다. -> 뒤로 가면 갈수록 학습이 점점 멈춰진다!

#### Adadelta

: adagrad의 G가 커지는 현상을 막은 것이다.

![adadelta](https://user-images.githubusercontent.com/59636424/128799117-be3e37fa-d4ea-4096-95ca-0a80b9577201.PNG)

-> 현재 timestep t가 주어졌을 때, t를 어느 정도 window size만큼에 시간에 대한 gradient 제곱의 변화를 본다!

-> window size 100을 잡으면 이전 100개 동안 G라는 정보를 들고 있어야 한다!

-> parameter가 많아지기 때문에 어떤 값이 있을 때, 감마를 통해 어느 정도 time window만큼의 값을 저장하고 그거에 따른 평균값, 합을 가지고 있게 된다.

-> **이러한 exponential moving average(EMA)로 large G_t를 업데이트를 한다!**

-> **learning rate가 없다!**

~~~
sum of squared gradients를 accumulate하는 것이 아니라, AdaDelta는 window of accumulated past gradients를 제한함으로서 고정된 싸이즈의 w값을 유지한다.

이전의 squared gradients값 w를 저장하는것은 비효율적이기 때문에, accumulation은 exponentially decaying average of the squared gradients로 구현한다.
~~~

#### RMSprop

![rmsprop](https://user-images.githubusercontent.com/59636424/128799621-a1e57bc0-4b38-4a9f-a422-5216b6f80a35.PNG)

: gradient squares의 EMA를 더해주어 그것을 분모에 넣고 stepsize로 계산한다.

#### Adam

: adam은 gradient squares를 EMA 가져감을 동시에, 모멘텀을 같이 활용한다.

![adam](https://user-images.githubusercontent.com/59636424/128799948-4f22b4de-c56f-4037-921e-01b2c3d75e1c.PNG)

-> hyper parameter 베타1(모멘텀을 얼마나 유지시킬지), 베타2(gradient squares의 EMA 정보) 등이 있다.


### Regularization

: generalization을 잘 되게 하고 싶은 것이다. -> 학습을 방해를 목적으로 하는 규제 -> 학습 데이터 만이 아니라 테스트 데이터에서도 잘 동작하도록 규제하는 것이다.

#### Early stopping

: error가 더 커지기 전에 멈추기!

#### Parameter Norm Penalty

![penalty](https://user-images.githubusercontent.com/59636424/128800330-23018a0c-fed9-4af5-884a-3b47a213aee1.PNG)

: 파라미터가 너무 커지지 않게 한다. -> 네트워크 파라미터를 제곱한 다음에 더하는 것 -> 네트워크 weight 숫자들이 작으면 작을 수록 좋다!(크기 관점)

#### Data Augmentation

: 데이터를 늘리기 위해서!

-> 데이터 각도를 돌리기 등의 label preserving augmentation으로 **label이 바뀌지 한도 내**에 변화시킨다!

#### Noise Robustness

: 입력 데이터에 노이즈를 넣는다. -> 단순히 입력에만 아니라 뉴럴 넷 weight에도 넣는다!

#### Label Smoothing

: data augmentation과 유사한데 데이터 2개를 뽑아서 섞어준다. => decision boundary를 부드럽게 만드나!

![smooth](https://user-images.githubusercontent.com/59636424/128800896-c11d36f2-4adc-4508-9b03-94e42567baa7.PNG)

* Mixup: 2개의 이미지를 라벨과 이미지를 섞는다!

* Cutout: 이미지에 일정 부분을 빼버린다.

* CutMix: 이미지 특정 영역에 서로 다른 label 이미지를 넣는다.

-> **이러한 방법이 성능이 많이 올라간다! (CutMix, Mixup!)**

#### Dropout

![zzz](https://user-images.githubusercontent.com/59636424/128801065-b7030069-fbe4-4a2b-beca-50d61f29a5e2.PNG)

: 뉴럴 넷의 weight를 0으로 바꿔준다!

#### Batch Normalization

: 뉴럴 넷 각각 layer가 1000개 파라미터 layer라면 각각의 100 값을 평균과 분산을 통해 다 0으로 줄여버린다.

-> feature 줄임으로 뉴럴 넷이 잘 학습된다.

-> Batch Normalization은 일반적으로 깊을수록 좋은 경향이 있다.

![zdh](https://user-images.githubusercontent.com/59636424/128801900-cbf10a74-c263-4fd1-9365-15d14511291a.PNG)

* Batch Norm: layer 전체를 줄인다.

* layer Norm: 각각 layer 정보를 줄인다.

* Instance Norm: 데이터 이미지 한 장 별로 줄인다.

* Group Norm: layer와 isntance 중간이다.


(출처: gradient descent 관련: http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html)

# 3. 과제 수행 과정 / 결과물 정리

: 어제 수행한 과제와 기초로 Model이 들어가는데 hidden layer를 추가할 시, 전의 hidden 차원과 현재 hidden 차원을 bias를 주어 linear로 저장하고 좀 더 쓰무스하게 하기 위해 activation function tanh도 넣어준다. 그래서 만든 layer들을 Sequential로 network를 만든 후, add_module로 계속 network에 layer를 추가한다.

그리고 Gradient Descent 방법들을 비교하기 위해서 SGD, Momentum, Adam 3가지를 비교할 것이다. 그래서 optm으로 각각 맞는 파라미터와 learning rate를 지정한다. 그 중에, Momentum은 momentum을 선언해줘야한다. 

이렇게 선언한 모델을 초기화 후, train 모델로 바꿔서 각각 forward, loss, zero_grad, backward, step으로 Adam, Momentum, SGD를 업데이터 시켜준다. 이 때, 같은 배치를 이용한다.

![zzzzz](https://user-images.githubusercontent.com/59636424/128806958-1ad1ef21-fc6f-4f2c-8132-e6d9492f32cb.PNG)

: 그 결과, Adam이 매우 빠르게 잘 맞췄고 그 다음으로, Momentum과 SGD 순으로 맞췄습니다.

이렇게 SGD와 Momentum이 차이가 나는 이유는 Momentum은 이전 gradient를 활용하고 반영하므로 데이터를 많이 보는 효과를 얻기 때문입니다. 그리고 그보다 더 좋은 Adam은 모멘텀과 adaptive learning rate를 합치기에 어느 파라미터를 줄이고 늘이는 것이 가능해 더 좋습니다.
