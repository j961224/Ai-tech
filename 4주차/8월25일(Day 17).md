# 1. 8월 25일 배운 것!

## 5. Model

### Design Model with Pytorch

### Pytorch

* raw level에 대한 장점이 있다.

* Pythonic 하다.

* Flexibility 하다.

-> code 이해하는 것만으로도 training을 이해할 수 있다.

### nn.Moudle

: Pytorch 모델의 모든 레이어는 nn.Module 클래스를 따른다.

-> Linear 등과 같은 것들이 모두 이 nn.Moudle을 상속받는다.

**__init__에서 정의한 또 다른 nn.Module이다.**

    파라미터 저장소라고 볼 수 있다.
    
**forward 함수**

    이 모델이 호출 되었을 때 실행 되는 함수이다.
    
    딥러닝 전파 방향대로 구현하는 부분이다
    

### nn.Module을 상속받은 모든 클래스의 공통된 특징(nn.Module Family)

    모든 nn.Module은 chlid modules를 가질 수 있다.
    
    모든 nn.Module은 forward() 함수를 가진다. -> 한번만 실행한 것으로 각각의 forward()가 실행된다.


### Parameters

: 모델에 정의되어 있는 modules가 가지고 있는 계산에 쓰일 Parameter

    각 모델 파라미터들은 data, grad, requires_grad 변수 등을 가지고 있다.
    
### Pytorch의 Pythonic

: Pythonic하다는 것의 장점이 있다.

-> 형식과 구조를 직접 모델 응용이 가능하다.

## 6. Model - Pretrained Model

### ImageNet

: 컴퓨터비전 역사 발전에 크게 기여했다.

### Pretrained Model

: 모델 일반화를 위해 매번 수 많은 이미지를 학습시키는 것은 비효율적이다!!


### torchvision.models

: 손쉽게 모델 구조와 Pretrained Weight를 다운로드 할 수 있다.

### Transfer Learning

: 이미지 넷으로 Pretrained 된 것을 가져와서 우리 것에 적용해 보는 것

#### CNN base 모델 구조 (simple)

Input + CNN Backbone + Classifier -> output

#### Code Check

* Torchvision model 구조

~~~
import torchvision.models as models

resnet18 = models.resnet18(pretrained=True)
~~~

**내가 설정한 문제와 비교가 필요하다!**

    Pretraining 할 때, 설정했던 문제와 현재 문제와의 유사성을 고려한다.
    
### Case by Case

* Case 1. 문제를 해결하기 위한 학습 데이터가 충분하다.

    input과 높은 유사성이 있다면 CNN Backbone을 freeze하고 classifier을 Trainable해서 output을 얻을 수 있다.
    
    input과 낮은 유사성이 있다면 CNN Backbone과 classifier를 Trainable해서 output을 얻을 수 있다. (아무것도 없는 파라미터보다는 좋다.)
    
 * Case 2. 학습 데이터가 충분하지 않은 경우

    input과 높은 유사성이 있다면 CNN Backbone을 freeze하고 classifier을 Trainable해서 output을 얻을 수 있다.


# 3. 마스크 착용 상태 분류 대회 3일차

## 시도 1. ResNet50 (정확도 53%, F1-score 0.43)

* 시도한 특징

        마스크 착용 유무, 나이, 성별 이렇게 18 class를 분류하는데 1번에 18 class를 분류했다.
        
        Data를 (224,224)로 resize와 ColorJitter, Normalize를 albumentation을 통해 수행했다. -> 또한 이미지로 변형 시, cv2.cvtColor로 RGB로 변형시켰다.
        
        class 불균형을 조금 극복하기 위해 Stratified K-Fold 5회 실시하였다.
      
     
* 개선할 점과 잘못된 점

        k-fold 시, 기본적은 epoch을 모두 1로 하여 당연히 성능이 안 좋게 나올 수 밖에 없었다.
        
        너무 1번에 18 class를 분류하려고 했다.
        
        처음에 1번 어떤지 맛 보기 위해 Data augmetation 등은 간단히 처음에 시도해봤어야 했는데 욕심이 있었다.


## 시도 2. EfficientNet b4 (정확도 77%, F1-score: 0.722)

* 시도한 특징

        이번에는 마스크 착용 유무 모델, 성별 모델, 나이 모델 이렇게 3가지로 나누어 18개의 class를 분류했다.
        
        Data를 이번에는 CenterCrop(380,380)으로 잘랐고 Normalize만 수행 -> 이미지 변형 시, cv2.cvtColor로 RGB로 변형시켰다.
        
        Stratified K-Fold를 모두 4번 수행했다.
        
        각각 모델마다 class_weight를 부여했고 CrossEntryopLoss로 criterion을 수행했다.
 
 * 개선할 점과 잘못된 점

        이미지 변형 시, cv2.cvtColor로 RGB로 변형시키지 않고 그냥 Image.open을 사용해보는 것도 나쁘지 않다고 생각한다. -> 마스크 색깔, 사진 찍을 시 조명 등등으로 RGB를 우선적으로 수행은 아쉬운 것 같다.
        
        이 경우도, epoch을 1번 돌렸던 것이 아쉬웠다. -> 다음 시도 시, epoch을 늘리고 early_stop을 이용해 최고 모델을 뽑아보자!
        
        3개의 모델 중에 나이 분류 모델의 성능이 안 좋았는데 좀 더 개선이 필요해 보인다. -> 따로 정규화나 Data augmentation을 다르게 시도해보자!
        
        나이 분류 모델 학습 시, inference로 어떤 지 맛만 보고 바로 모든 데이터를 학습해보는 시도도 수행해보자!
        
        VIT와 앙상블을 수행도 한 번 시도해 볼 만한 것 같다. -> 대신, VIT 시 이미지 사이즈를 좀 많이 덜어내야 되므로 잘 생각해서 적용하자!
        
        성별 분류는 이진분류이므로 Loss 수행 시, BCELoss도 고려해보자!
        
        사전 학습 모델의 모든 파라미터를 업데이터 시켰는데 이 부분에 대한 fine-tuning도 중요할 것이다!
  
