# 1. 8월 24일 공부한 것!

## 3강 Dataset

: Dataset을 만드는 것이 중요하다!

### Pre-processing(전처리)

#### Bounding box

: 가끔 필요 이상으로 많은 정보를 가지고 있기도 한다. (이번 것은 bounding box가 없지만 마스크가 중간에 있는 것을 생각해볼 수 있다.)

#### Resize

: 큰 사이즈의 경우, 학습을 하는데 많은 시간이 소요될 수 있다.

-> 효율적인 size를 찾는 것이 중요하다!!!

ex) 이미지를 밝기를 조절하는 것도 좋을 수 있다.


### Generalization

#### Bias & Variance

- Variance가 높으면 Overfitting이 일어나고 Bias가 높으면 Underfitting이 일어난다.

#### Train / Validation

: 훈련 셋 중 일정 부분을 따로 분리, 검징 셋으로 활용한다.

#### Data Augmentation

주어진 데이터가 가질 수 있는 경우, 상태의 다양성이 존재한다. (데이터 다양화 시키기!)

-> 밝기 조절, 회전 등 여러 noise로 좀 더 다양한 이미지를 훈련시킨다.

=> 모델의 쓰임새를 살펴보자!!

#### torchvision.transforms

#### Albumentations

: 좀 더 빠르고 다양한 것을 제공한다. (transforms보다)

=> 이 라이브러리를 이번 마스크 대회에 1번 사용해보자!!

## 4강 Data Generation

### Data Feeding

- Feed: 대상의 상태를 고려해서 적정한 양을 준다.

* 모델에 먹이를 준다는 의미는?

=> 모델에 처리할 수 있는 양이 있다면 Data Generator는 그보다 적다면 아무리 모델이 빠른 성능을 가지고 있더라도 Generator 이상으로는 안 나옴

* Transforms 시, resize 순서에 따라도 걸리는 시간 차이가 늘어난다.

### torch.utils.data

### Datasets의 구조

~~~
from torch.utils.data import Dataset #torch.utils.data의 Dataset 라이브러리 상속!

class Mydataset(Dataset):
  def __init__(self): # MyDataset 클래스가 처음 선언 되었을 때 호출
     pass
  
  def __getitem__(self, index): # MyDataset의 데이터 중 index 위치의 아이템을 리턴
     return None
  
  def __len__(self): # MyDataset 아이템의 전체 길이
     return None
~~~

### DataLoader

내가 만든 Dataset을 효율적으로 사용할 수 있도록 관련 기능 추가한 것이다.

-> batch_size, num_workers, shuffle, samepler 등을 사용할 수 있다.

-> collen_fn 기능은 배치마다 작업하고 적용하고 싶다면(함수를 적용하고 싶다면) 사용할 수 있다.

#### num_workers

: 클수록 thread를 더 사용하므로 학습 시간이 줄어든다.

# 2. 피어세션 정리

* 8월24일 (화) ONE AI 피어세션 회의록

    회의 안건 : Github에 대한 규칙 및 활용 방향 회의
    

~~~
1. Branch 관리

1-1. Git Flow

  1. Master Branch : Release
  2. Devloper Branch : 전체 개발용
  3. Feature Branch : 각자 Branch를 따로 만들어서 개발학 Developer Branch로 병합하기

1-2. 개발 과정
  1. 제출용 코드 -> Master Branch
  1. 개발의 규모가 크지 않기 때문에 Developer Branch를 따로 구성하지 않는다.
  2. 각자 개발하고 싶은 기능이 있으면 Branch를 따로 만들어서 개발하고 Master Branch에 병합하기

1-3. 주요 고려 사항
  1. Pull Request
    1. 개요 : 각자 Feature Branch에서 개발하고 Devloper Branch에 Merge하기 직전에 하느 단계. 
    2. 목표 : Merge를 하기 이전에 다른 팀원에게 확인받는 단계
    3. 작업 -> Push -> Pull Request
    4. 항목
      1. Reviewers : 현재 Pull Request(PR)을 리뷰를 해 줄 팀원을 지정한다.
      2. Assignees : 현재 PR 작업의 담당자를 지정해주면 된다.


  2. Issue
    1. 개요 : 새로운 추가될 가능, 개선 해야할 가능, 버그 등등 모든 활동 내역에 대해서 이슈를 등록하고 그 이슈기반으로 작업을 진행
    2. 등록하기
      1. Assignees : 해당 작업의 담당자
      2. Labels: 해당 작업의 성격
    3. Pull Request 와의 연결
      1. Pull Requset가 생성되면 새로우 Issue Number를 받게 되므로 Pull Request 또한 Issue에 해당이 된다.
      2. Pull Requset에서 다른 팀원들의 확인을 받ㄱ resolved 키워드를 입력하면 해당 Pull Requset가 master Branch에 반영되면서 Close된다.
    3. Pull Requset를 받으 Reviewr들은 Add your review 버튼을 클릭해서 코드 리뷰를 진행한다.
      1. Approve: 코드에 대한 의문점이 없다면 승인
      2. Comment: 간단한 피드백 제출
      3. Request changes: 해당 코드에 문제가 있다고 판단되며 코드를 반드시 수정 요구


  3. Commit Message
    1. 다른 사람들으 Commit을 이해하기 쉽게 간략하 메시지르 작성해주어야 하는데 그에 대한 규칙
    1. upload 첫 파일 올릴 때
    2. add 추가
    3. fix 에러 고침
    4. edit 수정
    5. test 테스트
    6. mv 파일, 폴더 옮김
    7. rm 지우기
    8. check: 확인
    9. fix img: 이미지 고침
    10. md clearup md 정리
    11. rename 이름 수정
~~~

# 3. 마스크 착용 상태 분류 대회 2일차

## 3-1. Train Dataset과 Test Dataset 구축하기

### 3-1-1. Train Dataset

* **Train Dataset의 __init__ 부분**

~~~
def __init__(self, data, label, transform=None):
        
        self.X=data
        self.y=label
        self.transform = transform
~~~

: Train Dataset에 train data를 self.X, 그 데이터에 맞는 label은 self.y, torchvision.transform을 받는 self.transform을 받는다.

* **Train Dataset의 __len__ 부분**

~~~
def __len__(self):
    return len(self.X)
~~~

: 받은 데이터의 수(길이)를 반환한다.

~~~
def __getitem__(self,idx):
    y = self.y[idx]
    X = self.X[idx]
    image = cv2.imread(X,cv2.IMREAD_COLOR)
    img = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
    if self.transform:
        img = self.transform(image=img)['image']
    img = img.transpose(2, 0, 1) # 어떤 모델을 쓰냐에 따라 transpose를 사용한다.
    img = torch.tensor(img,dtype=torch.float) # 어느정도 전처리한 데이터를 float 형태로 바꿔준다.
    y = torch.tensor(y,dtype=torch.long) # label을 tensor 형태로 바꿔준다. (long말고 float 형태도 가능!)
    return img,y
~~~

: 우선 받은 이미지 train 데이터를 cv2로 읽고 BGR을 RGB로 바꿔준다! 그리고 transform을 통해 이미지를 변형시켜 tensor형태로 반환한다. label 또한 바로 tensor 형태로 변환한다.

### 3-1-2. Test Dataset

* **Test Dataset의 __init__ 부분**

~~~
def __init__(self,transform=None):
        # train data csv 파일 불러오기
        test_dir = '/opt/ml/input/data/eval'
        test_data = pd.read_csv(os.path.join(test_dir, 'info.csv'))
        
        test_image_list=[]
        for i in test_data['ImageID']:
            test_image_list.append(test_dir+"/images/"+i)
        
        self.X = test_image_list
        self.transform = transform
~~~

: TestDataset은 Test data 중에 일부만 불러오는 경우가 거의 없다고 생각하여, init함수 안에서 test 이미지 데이터 경로를 만들어서 self.X에게 주고, 변형할 transform을 self.transform으로 받는다.

* **Test Dataset의 __len__ 부분**

~~~
def __len__(self):
    return len(self.X)
~~~

: Test data의 갯수(길이)를 반환한다.

* **Test Dataset의 __getitem__ 부분**

~~~
def __getitem__(self,idx):
        X = self.X[idx]
        # 아래 흐름은 Train Dataset과 유사!
        image = cv2.imread(X,cv2.IMREAD_COLOR)
        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
        if self.transform:
            image = self.transform(image=image)['image']
        img = image.transpose(2, 0, 1)
        img = torch.tensor(img,dtype=torch.float)
        return img
~~~

: 이 부분은 Train Dataset의 __getitem__ 부분에서 label을 제외하면 똑같다고 볼 수 있다.

## 3-2. Dataloader 구축하기

* train dataloader

~~~
DataLoader(train_dataset, batch_size=batch_size,shuffle=True)
~~~

: 이와 같이 train_dataset과 batch_size(32)와 shuffle을 True로 해줌으로 data를 섞는 DataLoader를 구축했다.

* test dataloader

~~~
DataLoader(test_dataset,batch_size=batch_size,shuffle=False)
~~~

: train dataloader와 유사하지만 Test Dataset을 받고 shuffle을 False로 해줌으로 데이터를 섞지 않는 DataLoader를 구축했다.
