# 1. 8월 27일 배운 것!

## 9. Ensemble

: 싱글 모델보다 더 나은 성능을 위해 서로 다른 여러 학습 모델을 사용하는 것!

* Low Bias, High Variance -> Overfitting!

### Model Averaging (Voting)

* Hard Voting: 손 들고 다수결로 가는 것!

-> 다른 모델에 대해서 잘 고려하지 않는다!

* Soft Voting: 각 class 확률을 모두 보고 점수들을 버리지 않는다는 것이다!

=> 다 고려하는 방법이다.

### Cross Validation

: 훈련 셋과 검증 셋을 분리하되, 검증 셋을 학습에 활용하는 방법은?!!

### Stratified K-Fold Cross Validation

: 가능한 경우를 모두 고려 + Split시에 Class 분포까지 고려

-> K가 적게 되면 일반화되기 쉽지 않다. => 보통은 5번 한다!

### TTA (Test Time Augmentation)

: 테스트 할 때 Augmentation을 어떻게 하는가?

-> 여러 다른 노이즈를 섞더라도 어느정도 잘 동작하도록 하는 것!

### 성능과 효율의 Trade-off

: 앙상블 효과는 확실히 있지만 그 만큼 학습, 추론 시간이 배로 소모된다.

### Hypterparameter

### Optuna

: 파라미터 범위를 주고 그 범위 안에서 trials 만큼 시행

## 10. Experiment Toolkits & Tips

### Training Visualization

* Tensorboard

: 학습 과정을 기록하고 트래킹 하는 것도 중요하다!

~~~
tensorboard
    --logdir PATH # log가 저장된 경로
    --host ADDR # 원격 서버에서 사용 시 0.0.0.0(default: localhost)
    --port PORT # 포트 번호
~~~

### Wegiht and Bias (wandb)

~~~
import wandb

wandb.init(config={"batch_size": 32, ~})
~~~

-> 이렇게 하면 페이지에서 로그 확인할 수 있다.

### Machine Learning Project

* Jupyter Notebook

: 코드를 아주 빠르게 Cell 단위로 실행해볼 수 있는 것이 장점이다.

또한 EDA를 할 때 사용하면 매우 편리하다!

### Python IDLE

: 구현은 한번만, 사용이 언제든, 간편한 코드 재사용이 가능하다!

-> 자유로운 실험 핸들링

## 3. 마스크 착용 상태 분류 대회 5일차

### 시도. EfficientNet50 + VIT (Acc: 79.0635%, F1-score: 0.7332)

* 시도한 특징

        마스크 분류 모델과 성별 분류 모델은 그대로 적용했다.
        
        니이 분류 모델은 efficientNet50(epoch 30, K-Fold 4, batch_size 32, 모든 파라미터 갱신) + VIT(K-Fold 4, batch_size 64, classifier 전체 갱신, 나머지 파라미터 * lr*0.5 갱신, epoch 4) => soft voting
        
* 개선할 점

        나이 분류 모델 중 efficientNet50 과적합 잡기 / VIT 좀 더 학습 및 learning rate 개선
