# 1. 9월 8일 배운 것!

## 1. Seq2Seq with attention Encoder-decoder architecture Attention mechanism

### Seq2Seq Model

many to many에 해당한다!

### Seq2Seq with attention

many to many 중에, **맨 앞에 넣었던 단어가 응답할 때, 유실될 가능성이 높다!**

차선책으로, 입력 문장의 순서를 뒤집어서 마지막 timestep에 첫 단어가 나오게 한 적이 있다.

![diqdiq](https://user-images.githubusercontent.com/59636424/132435175-b2fae01a-9c24-4ada-8c31-644002584b64.PNG)

    1. Encoder의 마지막 hidden state가 Decoder로 들어간다.

    2. Decoder RNN에 start token(x_1)의 word embedding vector가 주어진다.
    
    3. 그렇게 넣은 것이 Decoder hidden state vector 나온다. (h_1^d)
    
    4. h_1^d는 encoder hidden state들과 내적을 해서 Attention scores가 된다.
    
    5. softmax를 통해 Attention distribution(합이 1인 형태의 상대적인 가중치를 attention vector라고 한다.)이 나온다.
    
    6. 이러한 Attention distribution은 encoder hidden state에 부여되는 가중치로 사용!
    
    7. 이렇게 구한 것은 가중평균을 구할 수 있고 그것으로 하나의 encoding vector(attention output)를 구할 수 있다.
    
**encoder hidden state들과 decoder hidden state 1개가 attention module에 들어가서 가중평균 vector 1개가 output으로 나온다.**

**Decoder hidden state vector와 attention output vector가 concat이 되어서 다음 입력으로 들어간다.**

![wow](https://user-images.githubusercontent.com/59636424/132436923-00dc3f61-63b9-4d36-9449-33a345fd00fd.PNG)

    1. 2번째 timestep에서는 그 당시에 들어오는 것은 입력단어와 decoder hidden state vector가 들어온다.
    
    2. 그러면 decoder hidden state vector(h_2^d)가 들어온다.
    
    3. 앞과 동일한 모듈을 사용하되, h_2^d로 내적하여 Attention score -> distribution을 구한다
    
    4. 이러한 Attention distribution은 encoder hidden state에 부여되는 가중치로 사용!
    
    5. 이렇게 구한 것은 가중평균을 구할 수 있고 그것으로 하나의 encoding vector(attention output)를 구할 수 있다.

**이렇게 또, Decoder hidden state vector와 attention output vector가 concat이 되어서 다음 입력으로 들어간다.**

이렇게 계속 흘러간다!

**핵심인, Attention distribution으로 어떤 단어를 가져올지 가중치를 가져오고 이것을 Attention output이 어떤 단어를 예측할지에 영향을 준다.**

---

### Backpropagation

![wwwww](https://user-images.githubusercontent.com/59636424/132437964-cc6299e3-6673-4320-b6d0-258b4df48d6c.PNG)

    1. 예측했던 output을 decoder RNN과 Encoder RNN으로 돌아간다.
    
    2. 만일, 단어 예측할 때, encoder 정보를 잘 못 가져온 경우 Attention distribution을 원하는 정보가 선택될 수 있도록 업데이트한다.
    
    3. hidden state vector가 다시 Decoder RNN을 갱신한다.

**보통 초반에 output을 잘 못 예측하더라도 다음 timestep에 Ground Truth를 입력으로 넣어주게 된다.**

=> 이 방식은 Teacher Forcing이라고 한다!

### Different Attention Mechanisms

![weee](https://user-images.githubusercontent.com/59636424/132441559-dc8ebaa7-c27b-4c87-a4ce-5f2d6142394c.PNG)

1. 내적하는 방법

2. general 내적 방법

![ee](https://user-images.githubusercontent.com/59636424/132440800-48394f85-6588-467b-ab78-f0d6fbdea4bf.PNG)

    1번 내적 방법에서 가운데에 학습가능한 행렬을 둔다!
    
    보다 일반화된 dot product! -> 이러한 방법으로 attention module의 유사도를 결정해주는 학습 가능한 파라미터
    
3. concat 기반 attention

![qqqq](https://user-images.githubusercontent.com/59636424/132441456-7b9ec9db-01dc-44fa-ad82-c84ac8efeec4.PNG)

    decoder hidden state vector와 encoder 특정 word hidden state vector를 concat한다.
    
    그림의 W1(=Wa)을 거친다.
    
    tanh로 non linear를 만든다!
    
    두번째 layer에서는 W2(v_a^T)(왜 백터로 표현되었냐면 만약에 3차원 벡터가 있다면 W2는 scalar 값을 만들어야하므로 row벡터가 된다.)로 두 벡터의 유사도를 구해준다.
    
    결론으로 two layer의 neural net을 구할 수 있다!

**이러한 방식들로 attention score 부분에서 그전에는 학습가능한 파라미터가 포함되지 않았던 simple 내적을 학습이 필요로하는 파라미터가 포함된 모듈로 변경되었다.**

=> 이것은 Backpropagation을 통해서 유사도 구하는 모듈을 갱신한다. (Wa와 같은 가중치들)

## Attention is Great!

기계번역 분야에 성능을 올릴 수 있었다!

-> decoder의 매 timestep마다 어떤 부분을 집중하고 사용할지가 가능해짐!

bottleneck 문제를 해결!

-> 긴 문장에 대해서 번역이 어려웠는데 그것을 해결

학습 관점에서 기울기 소실 해결

-> LongTerm Dependency를 해결!

해석가능성을 제공해준다!

-> decoder가 각 단어를 예측할 때, 어떤 단어를 집중했는지 알 수 있다!

-> 어떤 단어를 봐야할지에 대한 aligment를 스스로 배울 수 있다!

## Attention Examples in Machine Translation

![rr](https://user-images.githubusercontent.com/59636424/132442508-06c7bb09-42fc-4410-8112-bbb600773624.PNG)

옆쪽이 encoder로 번역할 문장이고 위는 decoder로 번역된 문장이다.

그림을 보면 처음에서 4번째까지 attention이 순차적으로 번역을 했는데 그 다음에는 encoder 해당 단어 순서를 반대로 보아 align을 수행하여 단어를 예측했다.

적절한 attention pattern을 볼 수 있다!
