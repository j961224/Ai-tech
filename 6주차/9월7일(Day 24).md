# 1. 9월 7일 배운 것!

## RNN

![diq](https://user-images.githubusercontent.com/59636424/132228393-5af476a8-cf0f-49e2-beb9-bd2ea6289f44.PNG)

    sequence 데이터가 입출력으로 주어진 상황에 각 timestep sequence x_t와 
    
    전 timestep rnn 모듈에서 계산한 hidden state vector h_(t-1)을 입력으로 받아
    
    현재 timestep에서의 h_t를 출력으로 낸다.

    (A는 RNN 모듈이다.) -> 매 timestep마다 재귀적으로 호출!(A 모듈의 출력이 다음 timestep의 입력으로 들어가므로)
    
    task에 맞는 출력값 y를 계산해줘야한다!

![sssss](https://user-images.githubusercontent.com/59636424/132248617-6e0a52c8-dbab-4470-b92d-40e82e2439a9.png)

    x_t: timestep에 input vector(입력 벡터)
    
    h_(t-1): 전 timestep RNN에서 계산된 hidden state vector
    
    f_W: x_t와 h_(t-1)를 입력으로 받는 parameter W(RNN에 필요한 linear transformation matrix를 정의하는 parameter)를 가지는 RNN 함수
    
    h_t: 출력으로는 현재 timestep t에 대한 hidden state vector
    
    y_t: timestep t에서 최종 예측값에 대한 output을 계산해야하는 경우(h_t를 바탕으로 y_t를 계산)

y_t는 매 timestep마다 계산할 수도 있고 마지막 timestep에만 계산할 수 있다. 

-> 단어별로 품사 예측 시, 매 timestep마다 각 단어의 품사 예측 값이 나와야한다.

-> 문장 긍부정 시, 마지막 단어까지 읽은 뒤에 마지막 timestep에 대해서만 긍/부정 예측

**모든 timestep에서 RNN 모듈 정의하는 W는 동일한 값을 공유한다.**

---

* f_W를 정의

![wqwqwqwqwqwqw](https://user-images.githubusercontent.com/59636424/132230639-e3b306a3-ade2-43ca-a605-b302df7c9827.PNG)

timestep x_t가 3차원 벡터라고 생각하고 h_(t-1)이 2차원 벡터인 경우, h_t는 h_(t-1)과 동일한 dimension을 공유하므로 2차원이어야 한다!

-> x_t와 h_(t-1)로 h_t를 계산한다. -> **tanh**를 거쳐 최종적인 h_t를 계산할 수 있다.

![hh_tt](https://user-images.githubusercontent.com/59636424/132232447-6bdafdef-5ef7-4d1c-8545-c797fd15b4d5.PNG)

x_t와 h_(t-1) 차원 3차원, 2차원이라면 linear transformation을 통해 h_t가 나오면 W는 2 x 5로 정의된다!

    그러면 3열까지 W_xh고 4~5열은 W_hh로 표현가능하다!

W_hy x h_t = y_t -> binary classification이라면 y_t는 1차원이고 multi면 class 갯수만큼 차원을 가진다!

## 2. Types of RNNs

![onone](https://user-images.githubusercontent.com/59636424/132234749-e30cc2d8-a4a5-4607-9832-de7901d26a30.PNG)

> * one-to-one
> > 일반적인 모델 구조
> * one to may
> > 이미지 캡션에 사용 (입력으로 하나의 이미지 -> 이미지 설명 예측 or 생성에 필요한 단어를 timestep별로 생성)
> * many to one
> > 마지막 timestep으로 출력을 내준다. (감정분석)
> * many to many
> > 입출력이 sequence (machine translation -> 번역기)
> * 또 다른 many to many
> > 단어별로 문장이나 품사를 예측하는 경우(PoS tagging) / video classification(비디오가 timestep 마다의 이미지 frame이라고 하면 해당 frame이 어떤 신(전쟁 등)에 해당하는지 분류)

## 3. Character-level Language Model

![ewewewew](https://user-images.githubusercontent.com/59636424/132236377-95dae19b-58be-4fde-bfb9-38ca29765478.PNG)

hello로 우선 Character level Vocabulary 구축! -> 이러한 단어를 one-hot vector로 표현 가능!

![ss](https://user-images.githubusercontent.com/59636424/132236549-2df73f5d-8814-4b76-95bf-342fd986e1b9.PNG)

이렇게 표현한 one-hot vector를 다음과 같이 다음 character를 예측할 수 있어야 한다.

![gh_t](https://user-images.githubusercontent.com/59636424/132237268-c182fd83-5645-471f-89ea-2782e1291090.PNG)

실제로 hidden state vector를 계산한 것이다!

![output vector](https://user-images.githubusercontent.com/59636424/132237734-0b046068-a6ab-418d-a399-3a80af9434ca.PNG)

output vector는 input vector 차원과 같아야한다! -> output layer는 softmax를 통과한 결과로 가장 큰 값을 가진 단어를 선택한다.

---

![wewewewe](https://user-images.githubusercontent.com/59636424/132238324-2a34579a-e061-4413-a066-c0c8645c2b21.PNG)

이러한 방식으로 다음날 주식값을 예측가능하다! (output을 다음 input으로 넣어준다 -> 재사용!)

---

* 긴 문단에 대해서도 학습하기!

![kkkk](https://user-images.githubusercontent.com/59636424/132239076-a65e6157-321e-4a4f-90ae-791e8a18c1a3.PNG)

예시는 셰익스피어 작품으로 여기서 쉼표, 줄바꿈도 다 vocabulary에 넣는다!

![wewewewewewe](https://user-images.githubusercontent.com/59636424/132239320-6a0e0e7e-d0b9-468c-817d-dbb4a747df15.PNG)

초반 iteration에서는 첫 문자로 차례차례 문자 예측 시에는 좋은 성능이 보이지 않지만 계속 학습할수록 점점 더 학습이 잘 되는 것이 확인 가능하다.

---

* 추가로 논문이나 C code를 가지고 RNN을 통해 학습이 가능하다!

## BPTT(Backpropagation through time): 시간을 거슬러 올라간다는 표현!

![qqqqq](https://user-images.githubusercontent.com/59636424/132240553-46828f95-5cee-4e2b-a628-946731175657.PNG)

timestep t에 대한 입력 벡터의 linear transformation matrix(W_xh), 이전 hidden vector의 linear transformation matrix(W_hh), 출력값을 도출하는데 쓰이는 linear transformation matrix(W_hy)는 backpropagation에 의해서 학습이 진행된다.

* **여기서 왜 Backpropagation이 쓰이는가요??**

    W(linear transformation matrix)가 출력값의 오차에 따라 업데이트를 해야하는데 이게 Backpropagation이 수행해준다.
    
    거슬러 올라가면서 그 자리의 계수들을 업데이트 해준다!

* **Truncated-Backpropagation Through Time(생략된 BPTT)**

![eeee](https://user-images.githubusercontent.com/59636424/132241167-0fed2e2e-4828-449f-9903-697afdefa8b7.PNG)

**sequence가 길어지면 한꺼번에 처리하기에는 힘들다! -> 잘라서 제한된 길이에 대한 sequence만으로 학습하려한다!**

: 제한된 sequence를 7개로 1번에 학습하는 것을 한정한다면 7개씩 backpropagation으로 RNN parameter를 학습한다!

-> 이것이 **Truncated-Backpropagation Through Time(생략된-BPTT)**

**한 번더 말하자면 생략된 BPTT는 일정단위씩 끊어 역전파를 계산하며 그러므로 일정단위마다 오차를 다시 계산해줘야한다**

![wewewe](https://user-images.githubusercontent.com/59636424/132247046-e66008f9-a20f-41c5-8d94-74247354b446.png)

위의 사진은 10개씩 끊어 역전파를 해준 모습이다!

    
**RNN의 필요한 정보를 저장 공간은 매 timestep마다 update하는 hidden state vector이다.**

![erretet](https://user-images.githubusercontent.com/59636424/132241755-7fc03d4f-af39-47ad-81ee-ae77bc94137c.PNG)

특정한 hidden state dimension을 고정하고 해당 dimension 값이 어떻게 변화하는지를 크기가 마이너스로 크면 파란색이고 플러스로 크면 빨간색이다.

## Vanishing/Exploding Gradient Problem in RNN

![rtrtrt](https://user-images.githubusercontent.com/59636424/132244175-465a4d4d-0d47-4732-9ad5-50ce80b60d67.PNG)

original RNN은 동일한 matrix를 매 timestep에 곱한다.

-> W_hh가 반복적으로 곱함으로써(같은 숫자 계속 곱함) 기하급수적으로 커지거나 작아지는(공비가 1보다 작을 때) 패턴을 보인다.


![erererer](https://user-images.githubusercontent.com/59636424/132244530-b4965a92-5ad3-477b-b318-45cabeff8656.PNG)

y에서 gradient가 발생되었을때, backpropagation되서 h1까지 전달되면 h3에 대한 h1의 편미분을 구해준다!

-> 그렇게 되면, 미분과정에서 timestep을 거슬러 올라갈수록 3이 반복적으로 곱해지며 **gradient 계산 시에도 timestep 갯수만큼 3이 거듭제곱이 되어 증폭된다!**

* 만약 w_hh가 0.2라면??

    timestep의 차이만큼 곱해지며 0.2의 거듭제곱이 되면서 0으로 줄어든다.
    
**따라서 모델을 적절히 학습하는데 필요로하는데 gradient를 2 timestep을 넘어서 전달을 하게 되면 gradient가 기하급수적으로 커지거나 작아져 학습이 잘 안 된다.**

---

* **RNN에서는 tanh activation function을 사용했는데 왜 사용했을까?**

핵심만 먼저 말하자면 RNN의 기울기 소실 문제를 예방하고자 **gradient가 최대한 오래 유지될 수 있도록하기 위해 tanh가 적합**하다!

우선 **RELU를 쓰게 되면 0이상이라면 y=x이니 발산한 확률이 높아서 사용하지 않게 된다.** -> normalize가 되지 않는다!

* **그러면 값을 0~1로 normalize가 되는 sigmoid는??!**

우선 sigmoid와 tanh 미분한 그래프를 보자

![tanh](https://user-images.githubusercontent.com/59636424/132249100-7d7eefa7-417f-4979-a434-09f07ce24dd8.jpg)

그래프를 보면 tanh의 미분 최대값이 sigmoid에 비해 크다는 것을 알 수 있으니 **tanh에 비해 sigmoid가 기울기 소실 문제가 생길 가능성이 높다!**

그래서 **그나마 tanh를 이용해 gradient를 최대한 유지하려고 사용한다!**
